<!DOCTYPE html>
<html>
  <head>
    <title>Logistic Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="MACS 30100   University of Chicago" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Logistic Regression
### <a href="https://model.uchicago.edu">MACS 30100</a> <br /> University of Chicago

---




`$$\newcommand{\E}{\mathrm{E}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\Cov}{\mathrm{Cov}} \newcommand{\se}{\text{se}} \newcommand{\Lagr}{\mathcal{L}} \newcommand{\lagr}{\mathcal{l}}$$`

---

class: center

# Classification problems

[![RMS Titanic](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/RMS_Titanic_3.jpg/640px-RMS_Titanic_3.jpg)](https://youtu.be/FHG2oizTlpY?t=19)

---

class: center

# Classification problems

![[Titanic (1997)](https://en.wikipedia.org/wiki/Titanic_(1997_film))](https://i.giphy.com/KSeT85Vtym7m.gif)
    
---

# Classification problems

* Response is a qualitative variable
* Difference from regression problem
* Develop a model that assigns observations to categories or classes

---

# Titanic dataset


```
## Observations: 714
## Variables: 12
## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …
## $ Survived    &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0…
## $ Pclass      &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2…
## $ Name        &lt;chr&gt; "Braund, Mr. Owen Harris", "Cumings, Mrs. John Bradl…
## $ Sex         &lt;chr&gt; "male", "female", "female", "female", "male", "male"…
## $ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14…
## $ SibSp       &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0…
## $ Parch       &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0…
## $ Ticket      &lt;chr&gt; "A/5 21171", "PC 17599", "STON/O2. 3101282", "113803…
## $ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 2…
## $ Cabin       &lt;chr&gt; "", "C85", "", "C123", "", "E46", "", "", "", "G6", …
## $ Embarked    &lt;chr&gt; "S", "C", "S", "S", "S", "S", "S", "S", "C", "S", "S…
```

---

# A linear regression approach

`$$Y = \beta_0 + \beta_{1}X$$`

.center[

&lt;img src="logistic-regression_files/figure-html/titanic_ols-1.png" width="504" /&gt;

]

---

# A linear regression approach

`$$Y = \beta_0 + \beta_{1}X$$`

.center[

&lt;img src="logistic-regression_files/figure-html/titanic_ols_old-1.png" width="504" /&gt;

]

---

# Logistic regression

`$$\Pr(Y) = \Pr(\text{survival} = \text{yes} | \text{age})$$`

---

# The linear function

`$$f(X) = \beta_0 + \beta_{1}X$$`

.center[

&lt;img src="logistic-regression_files/figure-html/linear-demo-1.png" width="504" /&gt;

]

---

# The logistic function

$$
`\begin{align}
f(X) &amp;= \frac{e^{\beta_0 + \beta_{1}X}}{1 + e^{\beta_0 + \beta_{1}X}} \\
f(X) &amp;= \frac{1}{1 + e^{-(\beta_0 + \beta_{1}X)}}
\end{align}`
$$



.center[

&lt;img src="logistic-regression_files/figure-html/logit-demo-1.png" width="504" /&gt;

]

---

# Probability of surviving the Titanic

`$$\Pr(\text{Survival}) = \frac{e^{\beta_0 + \beta_{1}\text{Age}}}{1 + e^{\beta_0 + \beta_{1}\text{Age}}}$$`

--


```
## 
## Call:
## glm(formula = Survived ~ Age, family = binomial, data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.1488  -1.0361  -0.9544   1.3159   1.5908  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -0.05672    0.17358  -0.327   0.7438  
## Age         -0.01096    0.00533  -2.057   0.0397 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 960.23  on 712  degrees of freedom
## AIC: 964.23
## 
## Number of Fisher Scoring iterations: 4
```

---

class: center

# Probability of surviving the Titanic

&lt;img src="logistic-regression_files/figure-html/titanic_age_glm_plot-1.png" width="504" /&gt;

---

class: center

# Probability of surviving the Titanic

&lt;img src="logistic-regression_files/figure-html/titanic_age_glm_plot_wide-1.png" width="504" /&gt;

---

# Generating predicted probabilities



$$
`\begin{align}
\Pr(\text{Survival}) &amp;= \frac{e^{\beta_0 + \beta_{1} \times 30}}{1 + e^{\beta_0 + \beta_{1} \times 30}} \\
&amp;= \frac{e^{-0.0567236 + -0.0109635 \times 30}}{1 + e^{-0.0567236 + -0.0109635 \times 30}} \\
&amp;= 0.405
\end{align}`
$$

---

# Odds

`$$\frac{\Pr(Y)}{1 - \Pr(Y)} = e^{\beta_0 + \beta_{1}X}$$`

* Range is `\([0,\infty]\)`



.center[

&lt;img src="logistic-regression_files/figure-html/odds-demo-1.png" width="504" /&gt;

]

---

# Odds

`$$\frac{\Pr(\text{Survived})}{\Pr(\text{Died})}$$`

* Odds of `\(4\)`
* Odds of `\(\dfrac{1}{4}\)`

---

class: center

# Odds of surviving the Titanic

`$$\frac{\Pr(\text{Survival})}{1 - \Pr(\text{Survival})} = e^{\beta_0 + \beta_{1}\text{Age}}$$`

&lt;img src="logistic-regression_files/figure-html/titanic-odds-plot-1.png" width="504" /&gt;

---

# Log-odds

`$$\log\left(\frac{\Pr(X)}{1 - \Pr(x)}\right) = \beta_0 + \beta_{1}X$$`



.center[

&lt;img src="logistic-regression_files/figure-html/log-odds-demo-1.png" width="504" /&gt;

]

---

# Log-odds of surviving the Titanic

`$$\log\left(\frac{\Pr(\text{Survival})}{1 - \Pr(\text{Survival})}\right) = \beta_0 + \beta_{1}\text{Age}$$`

--


```
## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  -0.0567   0.174      -0.327  0.744 
## 2 Age          -0.0110   0.00533    -2.06   0.0397
```

`$$\log\left(\frac{\Pr(\text{Survival})}{1 - \Pr(\text{Survival})}\right) = -0.0567236 + -0.0109635 \times \text{Age}$$`

---

class: center

# Log-odds of surviving the Titanic

&lt;img src="logistic-regression_files/figure-html/log-odds-plot-1.png" width="504" /&gt;

---

# First difference



$$
`\begin{align}
\Pr(\text{Survival}_{30 - 20}) &amp;= \frac{e^{\beta_0 + \beta_{1}30}}{1 + e^{\beta_0 + \beta_{1}30}} - \frac{e^{\beta_0 + \beta_{1}20}}{1 + e^{\beta_0 + \beta_{1}20}} \\
&amp;= \frac{e^{-0.0567236 + -0.0109635 \times 30}}{1 + e^{-0.0567236 + -0.0109635 \times 30}} - \frac{e^{-0.0567236 + -0.0109635 \times 20}}{1 + e^{-0.0567236 + -0.0109635 \times 20}} \\
&amp;= 0.4047704 - 0.4314365 \\
&amp;= -0.0267
\end{align}`
$$

--



$$
`\begin{align}
\Pr(\text{Survival}_{50 - 40}) &amp;= \frac{e^{\beta_0 + \beta_{1}50}}{1 + e^{\beta_0 + \beta_{1}50}} - \frac{e^{\beta_0 + \beta_{1}40}}{1 + e^{\beta_0 + \beta_{1}40}} \\
 &amp;= \frac{e^{-0.0567236 + -0.0109635 \times 50}}{1 + e^{-0.0567236 + -0.0109635 \times 50}} - \frac{e^{-0.0567236 + -0.0109635 \times 40}}{1 + e^{-0.0567236 + -0.0109635 \times 40}} \\
&amp;= 0.3532243 - 0.3786548 \\
&amp;= -0.0254
\end{align}`
$$

---

class: center

# Plotting predicted probabilities







&lt;img src="logistic-regression_files/figure-html/plot_pred-1.png" width="504" /&gt;

---

class: center

# Women and children first

![](https://upload.wikimedia.org/wikipedia/commons/3/37/Wreck_of_the_Birkenhead.jpg)

---

# Multiple predictors

`$$\Pr(Y) = \frac{e^{\beta_0 + \beta_{1}X_1 + \dots + \beta_{p}X_{p}}}{1 + e^{\beta_0 + \beta_{1}X_1 + \dots + \beta_{p}X_{p}}}$$`

`$$\Pr(\text{Survival}) = \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex}}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex}}}$$`

--


```
## 
## Call:
## glm(formula = Survived ~ Age + Sex, family = binomial, data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.7405  -0.6885  -0.6558   0.7533   1.8989  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  1.277273   0.230169   5.549 2.87e-08 ***
## Age         -0.005426   0.006310  -0.860     0.39    
## Sexmale     -2.465920   0.185384 -13.302  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 749.96  on 711  degrees of freedom
## AIC: 755.96
## 
## Number of Fisher Scoring iterations: 4
```

---

class: center

# Multiple predictors



&lt;img src="logistic-regression_files/figure-html/survive_age_woman_plot-1.png" width="504" /&gt;

---

# Predicted probabilities and first differences in multiple variable models

* Log-odds functional form
* Predicted probability functional form

--

`$$\Pr(Y) = \frac{e^{\beta_0 + \beta_{1}X_1 + \beta_{2}X_2}}{1 + e^{\beta_0 + \beta_{1}X_1 + \beta_{2}X_2}}$$`

---

# Predicted probabilities and first differences in multiple variable models


```
## # A tibble: 3 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  -0.417    0.186       -2.24 2.49e- 2
## 2 Age          -0.0176   0.00567     -3.10 1.92e- 3
## 3 Fare          0.0173   0.00262      6.60 4.23e-11
```



---

# Predicted probabilities and first differences in multiple variable models

.pull-left[

`$$\log\left(\frac{\Pr(\text{Survival})}{1 - \Pr(\text{Survival})}\right) = \beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Fare}$$`

`$$\log\left(\frac{\Pr(\text{Survival})}{1 - \Pr(\text{Survival})}\right) = (\beta_0 + \beta_{2}\text{Fare}) + \beta_{1}\text{Age}$$`

]

.pull-right[

&lt;img src="logistic-regression_files/figure-html/fd-non-parallel-logodds-1.png" width="504" /&gt;

]

---

# Predicted probabilities and first differences in multiple variable models

.pull-left[

`$$\Pr(\text{Survival}) = \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Fare}}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Fare}}}$$`

`$$\Pr(\text{Survival}) = \frac{e^{(\beta_0 + \beta_{2}\text{Fare}) + \beta_{1}\text{Age}}}{1 + e^{(\beta_0 + \beta_{2}\text{Fare}) + \beta_{1}\text{Age}}}$$`

]

.pull-right[

&lt;img src="logistic-regression_files/figure-html/fd-non-parallel-prob-1.png" width="504" /&gt;

]

---

# Interactive terms

`$$\Pr(\text{Survival}) = \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex}}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex}}}$$`

--

`$$\Pr(\text{Survival}) = \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex} + \beta_{3} \times \text{Age} \times \text{Sex}}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{2}\text{Sex} + \beta_{3} \times \text{Age} \times \text{Sex}}}$$`

---

# Interaction terms


```
## # A tibble: 4 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)   0.594     0.310       1.91 0.0557 
## 2 Age           0.0197    0.0106      1.86 0.0624 
## 3 Sexmale      -1.32      0.408      -3.23 0.00125
## 4 Age:Sexmale  -0.0411    0.0136     -3.03 0.00241
```

--

$$
`\begin{align}
\Pr(\text{Survival}_{female}) &amp;= \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age} \times 0}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age} \times 0}} \\
&amp;= \frac{e^{\beta_0 + \beta_{1}\text{Age}}}{1 + e^{\beta_0 + \beta_{1}\text{Age}}}
\end{align}`
$$

--

$$
`\begin{align}
\Pr(\text{Survival}_{male}) &amp;= \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age} \times 1}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age} \times 1}} \\
&amp;= \frac{e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age}}}{1 + e^{\beta_0 + \beta_{1}\text{Age} + \beta_{3} \times \text{Age}}} \\
&amp;= \frac{e^{\beta_0 + (\beta_{1} + \beta_{3})\text{Age}}}{1 + e^{\beta_0 + (\beta_{1} + \beta_{3})\text{Age}}}
\end{align}`
$$

---

class: center

# Interaction terms



&lt;img src="logistic-regression_files/figure-html/age_woman_plot_logodds-1.png" width="504" /&gt;

---

class: center

# Interaction terms

&lt;img src="logistic-regression_files/figure-html/age_woman_plot_prob-1.png" width="504" /&gt;

---

# Evaluating model accuracy

* Error rate
* Proportional reduction in error
* Receiver operating characteristics (ROC) curve and area under the curve (AUC)

---

# Error rate



* Convert predicted probabilities into predictions
* Compare predictions to observed value
* Fraction incorrectly predicted is the error rate
--

* Age only model - `\(40.6\%\)` error rate
* What is the baseline for comparison?

---

# Useless classifier



* All predictions based on the modal category
* Titanic baseline - everyone dies
--

* Age only model - `\(40.6\%\)` error rate
* Useless classifier - `\(40.6\%\)` error rate

---

# Useless classifier

.center[

&lt;img src="logistic-regression_files/figure-html/plot-pred2-1.png" width="504" /&gt;

]

--



* Age x sex model -   22% error rate

---

# Proportional reduction in error

`$$PRE = \frac{E_1 - E_2}{E_1}$$`

* `\(E_1\)`
* `\(E_2\)`
* Ranges between `\([0,1]\)` or `\([0\%,100\%]\)`

---

# Proportional reduction in error



## Age-only model

$$
`\begin{align}
PRE_{\text{Age}} &amp;= \frac{290 - 290}{290} \\
&amp;= \frac{0}{290} \\
&amp;= 0\%
\end{align}`
$$

--

## Age x sex model

$$
`\begin{align}
PRE_{\text{Age x Sex}} &amp;= \frac{290 - 157}{290} \\
&amp;= \frac{133}{290} \\
&amp;= 45.9\%
\end{align}`
$$

---

class: center

# Types of error

![](https://marginalrevolution.com/wp-content/uploads/2014/05/Type-I-and-II-errors1-625x468.jpg)

---

# Confusion matrix ($.5$ threshold)


```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 360  93
##          1  64 197
##                                         
##                Accuracy : 0.7801        
##                  95% CI : (0.7479, 0.81)
##     No Information Rate : 0.5938        
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.5369        
##  Mcnemar's Test P-Value : 0.02544       
##                                         
##             Sensitivity : 0.8491        
##             Specificity : 0.6793        
##          Pos Pred Value : 0.7947        
##          Neg Pred Value : 0.7548        
##              Prevalence : 0.5938        
##          Detection Rate : 0.5042        
##    Detection Prevalence : 0.6345        
##       Balanced Accuracy : 0.7642        
##                                         
##        'Positive' Class : 0             
## 
```

---

# Alternative thresholds

* Sensitivity/recall

`$$TPR = \frac{\text{Number of actual positives correctly predicted}}{\text{Number of actual positives}}$$`

--

* Specificity

`$$TNR = \frac{\text{Number of actual negatives correctly predicted}}{\text{Number of actual negatives}}$$`

--

* Establishing threshold for predictions
* Improving class-specific accuracy

---

# Confusion matrix ($.8$ threshold)


```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 413 253
##          1  11  37
##                                           
##                Accuracy : 0.6303          
##                  95% CI : (0.5937, 0.6658)
##     No Information Rate : 0.5938          
##     P-Value [Acc &gt; NIR] : 0.02556         
##                                           
##                   Kappa : 0.1171          
##  Mcnemar's Test P-Value : &lt; 2e-16         
##                                           
##             Sensitivity : 0.9741          
##             Specificity : 0.1276          
##          Pos Pred Value : 0.6201          
##          Neg Pred Value : 0.7708          
##              Prevalence : 0.5938          
##          Detection Rate : 0.5784          
##    Detection Prevalence : 0.9328          
##       Balanced Accuracy : 0.5508          
##                                           
##        'Positive' Class : 0               
## 
```

---

class: center

# Alternative thresholds

&lt;img src="logistic-regression_files/figure-html/threshold-compare-1.png" width="504" /&gt;

---

# Receiver operating characteristics (ROC) curve

.center[

&lt;img src="logistic-regression_files/figure-html/roc-ggplot-1.png" width="504" /&gt;

]

--

* Area under the curve
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
