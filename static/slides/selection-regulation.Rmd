---
title: "Linear Model Selection and Regulation"
author: "[MACS 30100](https://model.uchicago.edu) <br /> University of Chicago"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      beforeInit: "macros.js"
      highlightLanguage: r
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE,
                      fig.retina = 2)

library(tidyverse)
library(tidymodels)
library(glmnet)
library(leaps)
library(here)
library(rcfss)
library(patchwork)

set.seed(1234)
theme_set(theme_minimal(base_size = 16))
```

$$\newcommand{\E}{\mathrm{E}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\Cov}{\mathrm{Cov}} \newcommand{\se}{\text{se}} \newcommand{\Lagr}{\mathcal{L}} \newcommand{\lagr}{\mathcal{l}}$$

---

# Linear model

$$Y = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p + \epsilon$$

* Least squares
* Adaptations of the linear model
    * Non-linear, additive, relationships
    * Alternative model fitting strategies
* Prediction accuracy
* Model interpretability

---

# Alternatives to least squares

* Subset selection
* Shrinkage (regularization)
* Dimension reduction

---

# Ames housing data

```{r ames}
ames_split <- initial_split(AmesHousing::make_ames(), prop = .7, strata = "Sale_Price")
ames_train <- training(ames_split)
ames_test  <- testing(ames_split)

glimpse(ames_train)
```

---

# Subset selection

* Fit separate least squares regression to each possible combination of the $p$ predictors

1. Let $M_0$ denote the null model, which contains no predictors. This model simply predicts the sample mean for each observation.
1. For $k = 1, 2, \ldots, p$:
    * Fit $\binom{p}{k}$ models, and call it $M_k$
    * Pick the best among the $\binom{p}{k}$ models, and call it $M_k$
1. Select a single best model from among $M_0, \ldots, M_p$

---

# Subset selection

```{r ames-subset, dependson = "ames"}
ames_lite <- ames_train %>%
  select_if(is.numeric)
best_subset <- regsubsets(Sale_Price ~ ., ames_lite, nvmax = 40)
summary(best_subset)$outmat
```

---

# Subset selection

* Computationally intractable - search space is too large
* Requires estimating $2^p$ models
    * $p = 10 \leadsto 2^{10} = `r 2^10`$ possible models
    * $p = `r ncol(ames_train) - 1` \leadsto 2^{`r ncol(ames_train) - 1`} = `r 2^(ncol(ames_train) - 1)`$ possible models
* Does not evaluate statistical significance of individual coefficients

---

# Forward stepwise selection

* Begin with null model, add predictors one at at time
* Only keep the variable which improves the model the most
* Requires fitting $1 + \sum_{k=0}^{p-1} (p-k) = 1 + \frac{p(p+1)}{2}$ models

--

1. Let $M_0$ denote the null model, which contains no predictors
1. For $k = 0, \ldots, p-1$:
    * Consider all $p-k$ models that augment the predictors in $M_k$ with one additional predictor
    * Choose the best among these $p-k$ models and call it $M_{k+1}$
1. Select a single best model from among $M_0, \ldots, M_p$

---

# Forward stepwise selection

```{r ames-forward, dependson = c("ames", "ames-subset")}
forward <- regsubsets(Sale_Price ~ ., ames_lite, nvmax = 40, method = "forward")
summary(forward)$outmat
```

---

# Backward stepwise selection

* Begin with full least squares model, remove predictors one at at time

--

1. Let $M_p$ denote the full model, which contains all $p$ predictors
1. For $k = p, p-1, , \ldots, 1$:
    * Consider all $k$ models that contain all but one of the predictors in $M_k$ for a total of $k - 1$ predictors
    * Choose the best among these $k$ models and call it $M_{k-1}$
1. Select a single best model from among $M_0, \ldots, M_p$

---

# Backward stepwise selection

```{r ames-backward, dependson = c("ames", "ames-subset")}
backward <- regsubsets(Sale_Price ~ ., ames_lite, nvmax = 40, method = "backward")
summary(backward)$outmat
```

---

# Comparing models

* Select the **best** model based on test error
* Indirectly estimate test error
* Directly estimate test error

---

# Indirect tests

| Statistic | Objective | Equation |
|--------------------------------------|-----------|--------------------------------------------------------------|
| $C_p$ | Minimize | $C_p = \frac{1}{n} (RSS + 2d\hat{\sigma}^2)$ |
| Akaike information criterion (AIC) | Minimize | $AIC = \frac{1}{n\hat{\sigma}^2} (RSS + 2d\hat{\sigma}^2)$ |
| Bayesian information criterion (BIC) | Minimize | $BIC = \frac{1}{n}(RSS + \log(n) d\hat{\sigma}^2)$ |
| Adjusted $R^2$ | Maximize | $\text{adj} \, R^2 = 1 - \frac{RSS / (n - d - 1)}{TSS / (n-1)}$ |

* $d$ - number of predictors
* $\sigma^2$ - estimate of the variance of the error $\epsilon$

---

# Subset selection

```{r ames-subset-stats, dependson = "ames-subset", fig.width = 12}
results <- summary(best_subset)

# best models per each metric
results_best <- tibble(
  `adj_r2` = which.max(results$adjr2),
  BIC = which.min(results$bic),
  `c_p` = which.min(results$cp)
) %>%
  gather(statistic, best)

# extract and plot results
tibble(`c_p` = results$cp,
       `adj_r2` = results$adjr2,
       BIC = results$bic) %>%
  mutate(predictors = row_number()) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line() +
  geom_point() +
  geom_vline(data = results_best,
             aes(xintercept = best, color = statistic), linetype = 2) +
  facet_wrap(~ statistic, scales = "free") +
  scale_color_brewer(type = "qual", guide = FALSE) +
  ggtitle("Subset selection")
```

---

# Subset selection

```{r ames-best-coef, dependson = "ames-subset-stats", fig.width = 12}
coef(best_subset, results_best$best) %>%
  set_names(results_best$best) %>%
  map(enframe) %>%
  bind_rows(.id = "num_vars") %>%
  filter(name != "(Intercept)") %>%
  ggplot(aes(name, value)) +
  geom_point(aes(color = num_vars), position = "dodge") +
  scale_color_brewer(type = "qual") +
  coord_flip() +
  labs(x = "Variable",
       y = "Estimated coefficient",
       color = "Number of variables\nin model") +
  theme(legend.position = "bottom")
```

---

# Stepwise forward selection

```{r ames-forward-stats, dependson = "ames-forward", fig.width = 12}
results <- summary(forward)

# best models per each metric
results_best <- tibble(
  `adj_r2` = which.max(results$adjr2),
  BIC = which.min(results$bic),
  `c_p` = which.min(results$cp)
) %>%
  gather(statistic, best)

# extract and plot results
tibble(`c_p` = results$cp,
       `adj_r2` = results$adjr2,
       BIC = results$bic) %>%
  mutate(predictors = row_number()) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line() +
  geom_point() +
  geom_vline(data = results_best,
             aes(xintercept = best, color = statistic), linetype = 2) +
  facet_wrap(~ statistic, scales = "free") +
  scale_color_brewer(type = "qual", guide = FALSE) +
  ggtitle("Stepwise forward selection")
```

---

# Stepwise backward selection

```{r ames-backward-stats, dependson = "ames-backward", fig.width = 12}
results <- summary(backward)

# best models per each metric
results_best <- tibble(
  `adj_r2` = which.max(results$adjr2),
  BIC = which.min(results$bic),
  `c_p` = which.min(results$cp)
) %>%
  gather(statistic, best)

# extract and plot results
tibble(`c_p` = results$cp,
       `adj_r2` = results$adjr2,
       BIC = results$bic) %>%
  mutate(predictors = row_number()) %>%
  gather(statistic, value, -predictors) %>%
  ggplot(aes(predictors, value, color = statistic)) +
  geom_line() +
  geom_point() +
  geom_vline(data = results_best,
             aes(xintercept = best, color = statistic), linetype = 2) +
  facet_wrap(~ statistic, scales = "free") +
  scale_color_brewer(type = "qual", guide = FALSE) +
  ggtitle("Stepwise backward selection")
```

---

# Indirect tests

1. Different subsetting procedures (best subset vs. forward stepwise vs. backward stepwise) will likely identify different "best" models
1. Different indirect error test estimate statistics will likely identify different "best" models

---

# Direct tests

* Validation/cross-validation approach

---

# Subset selection

```{r ames-model-mat, dependson = c("ames", "ames-subset")}
test_m <- model.matrix(Sale_Price ~ ., data = select_if(ames_test, is.numeric))
```

```{r ames-subset-test-mse, dependson = "ames-model-mat", fig.width = 12}
tibble(
  nvars = seq(from = 1, to = 33)
) %>%
  mutate(coef = map(nvars, ~ coef(best_subset, id = .x)),
         pred = map(coef, ~ test_m[ , names(.x)] %*% .x)) %>%
  unnest(pred) %>%
  group_by(nvars) %>%
  mutate(truth = ames_test$Sale_Price) %>%
  mse(truth = truth, estimate = pred) %>%
  ggplot(aes(nvars, .estimate)) +
  geom_line() +
  geom_point() +
  labs(x = "Number of variables",
       y = "Validation set test MSE")
```

---

# Subset selection cross-validation

* Perform best subset selection within each of the $k$ training sets
* May lead to different selection of variables for each model

```{r ames-subset-cv, dependson = "ames-subset", message = FALSE, fig.width = 12}
# predict function for regsubsets object
predict.regsubsets <- function(object, newdata, id ,...) {
  form <- as.formula(Sale_Price ~ .) 
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  as.vector(mat[, xvars] %*% coefi, mode = "integer")
}

predict_all <- function(object, newdata, k){
  map(k, ~ predict.regsubsets(object, newdata, id = .x)) %>%
    set_names(k)
}

ames_lite_cv <- vfold_cv(ames_lite, v = 10)

ames_lite_cv <- ames_lite_cv %>%
  mutate(model = map(splits, ~ regsubsets(Sale_Price ~ ., data = analysis(.x), nvmax = 40)),
         pred = map2(model, splits, ~ predict_all(.x, assessment(.y), k = 1:33))) %>%
  unnest(pred, .preserve = splits) %>%
  group_by(id) %>%
  mutate(k = 1:33,
         truth = map(splits, ~ assessment(.x)$Sale_Price)) %>%
  unnest(pred, truth) %>%
  group_by(id, k) %>%
  mse(truth = truth, estimate = pred) %>%
  group_by(k) %>%
  summarize(.estimate = mean(.estimate))

ggplot(ames_lite_cv, aes(k, .estimate)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = which.min(ames_lite_cv$.estimate), linetype = 2) +
  labs(title = "Subset selection",
       x = "Number of variables",
       y = "10-fold CV MSE")
```

---

# Subset selection

```{r ames-subset-final, dependson = "ames-subset"}
final_best <- regsubsets(Sale_Price ~ ., data = ames_lite, nvmax = 40)
coef(final_best, which.min(ames_lite_cv$.estimate))
```
