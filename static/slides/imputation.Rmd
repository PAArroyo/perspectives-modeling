---
title: "Imputation methods"
author: "[MACS 30200](https://github.com/css-research/course/) <br /> University of Chicago"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE,
                      fig.retina = 2, fig.width = 12)

library(tidyverse)
library(broom)
library(forcats)
library(modelr)
library(stringr)
library(car)
library(rcfss)
library(RColorBrewer)
library(here)

set.seed(1234)
theme_set(theme_minimal(base_size = 16))
```

$$\newcommand{\E}{\mathrm{E}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\Cov}{\mathrm{Cov}} \newcommand{\se}{\text{se}} \newcommand{\Lagr}{\mathcal{L}} \newcommand{\lagr}{\mathcal{l}}$$

---

# Causes of missingness

* Surveys
    * Global or unit non-response
    * Item non-response
* Errors in data collection
* Intentionally built into the research design (e.g. survey experiments)
* Censored values

---

# Patterns of missingness

* Missing completely at random (MCAR)
* Missing at random (MAR)
* Missing not at random (MNAR)

## Why does it matter?

* Mechanism for missingness
* Ignorable vs. non-ignorable

---

# Simulated data

```{r sim-data, include = FALSE}
n_sim <- 250 # Number of random samples

# Target parameters for univariate normal distributions
rho <- 2 / 3

mu1 <- 10
mu2 <- 20

s1 <- 9
s2 <- 16
s1s2 <- sqrt(s1) * sqrt(s2) * rho

# Parameters for bivariate normal distribution
mu <- c(mu1, mu2) # Mean 
sigma <- matrix(c(s1, s1s2, s1s2, s2), 2) # Covariance matrix
data_sim <- MASS::mvrnorm(n_sim, mu, sigma) %>%
  as_tibble %>%
  rename(x1 = V1,
         x2 = V2)
```

```{r sim-mod, echo = FALSE}
# plot of data
ggplot(data_sim, aes(x1, x2)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Complete data",
       x = expression(X[1]),
       y = expression(X[2]))
```

---

# Missing completely at random

```{r sim-mcar, echo = FALSE}
mcar <- data_sim %>%
  mutate(na = ifelse(row_number(x2) %in% sample(seq_len(n_sim), 100), TRUE, FALSE))

ggplot(mcar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mcar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing completely at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing")
```

---

# Missing at random

$$\Pr(X_{i2} \text{is missing}) = \frac{1}{1 + \exp[\frac{1}{2} + \frac{2}{3}(X_{i1} - 10)]}$$

```{r sim-mar, echo = FALSE, fig.height = 6}
mar <- data_sim %>%
  mutate(na = .5 + (2 / 3) * (x1 - 10) + rnorm(n_sim, sd = 2),
         na = logit2prob(na),
         na = as.logical(round(na)))

ggplot(mar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing")
```

---

# Missing not at random

$$\Pr(X_{i2} \text{is missing}) = \frac{1}{1 + \exp[\frac{1}{2} + \frac{1}{2}(X_{i2} - 20)]}$$

```{r sim-mnar, echo = FALSE, fig.height = 6}
mnar <- data_sim %>%
  mutate(na = .5 + (1 / 2) * (x2 - 20) + rnorm(n_sim, sd = 2),
         na = logit2prob(na),
         na = as.logical(round(na)))

ggplot(mnar, aes(x1, x2)) +
  geom_point(aes(alpha = na)) +
  geom_smooth(data = filter(mnar, !na),
              aes(color = "Non-missing values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  geom_smooth(aes(color = "All values"),
              method = "lm", se = FALSE, fullrange = TRUE) +
  scale_color_brewer(palette = "Dark2") +
  scale_alpha_manual(values = c(.3, 1)) +
  labs(title = "Missing not at random",
       x = expression(X[1]),
       y = expression(X[2]),
       color = "Regression line",
       alpha = "Missing")
```

---

# Traditional approaches to missing data

1. Does the method provide **consistent estimates** of the population parameters?
1. Does the method provide **valid statistical inferences**?
1. Does the method use the observed data **efficiently** or does it recklessly discard information?

---

# Complete-case analysis

* Listwise or casewise deletion
* Ignore any observations with missing values on variables necessary to estimate the model

## Benefits

* Is simple
* Provides consistent estimates and valid inferences when the data is MCAR
* Provides consistent estimates of regression coefficients and valid inferences when missingness on all the variables in a regression does not depend on the response variable

## Drawbacks

* Decreases efficiency
* When data is MAR or MNAR, listwise deletion provides biased results and invalid inferences

---

# Available-case analysis

* Pairwise deletion
* Use all non-missing observations to compute each statistic of interest
* For OLS:
    * Compute regression coefficients from means, variances, and covariances rather than directly from the observations

## Benefits

* Uses more information than complete-case analysis

## Drawbacks

* Less efficient than complete-case analysis
* Can lead to nonsensical statistical values
* Difficult to implement outside of OLS

---

# Imputation

* Fill in missing data with plausible imputed values
* Use complete data set to analyze using traditional methods

--

## Unconditional mean imputation

* Replace missing value with arithmetic mean/median/mode of the observed values
* Preserves measure of central tendency
* Decreases variance and covariance
* Potentially biases models and inferences even if data is MCAR

--

## Conditional mean imputation

* Replace missing data with predicted values obtained from a statistical learning model
* Use available variables to predict a single variable with missing values
* Replace missing values with predictions from the model
* Imputed values still tend to be less variable than the real data because they lack residual variation
* Fail to account for uncertainty in the model used to obtain the imputed values

---

# Comparison of imputation methods

```{r compare-imputation, fig.show = "hide", echo = FALSE}
get_miss_stat <- function(df){
  df %>%
    summarize(mu_1 = mean(x1, na.rm = TRUE),
              mu_2 = mean(x2, na.rm = TRUE),
              sigma_1 = var(x1, use = "complete.obs"),
              sigma_2 = var(x2, use = "complete.obs"),
              sigma_12 = cov(., use = "complete.obs")[1, 2],
              rho = cor(., use = "complete.obs")[1, 2],
              beta_12 = lm(x2 ~ x1, data = .) %>% coef(.) %>% .[[2]],
              beta_21 = lm(x1 ~ x2, data = .) %>% coef(.) %>% .[[2]]
    )
}

data_miss <- list(
  mcar = data_sim %>%
    mutate(x2 = replace(x2, sample(seq_len(n_sim), 100), NA)),
  mar = data_sim %>%
    mutate(na = .5 + (2 / 3) * (x1 - 10) + rnorm(n_sim, sd = 2),
           na = logit2prob(na),
           na = as.logical(round(na)),
           x2 = replace(x2, na, NA)) %>%
    select(-na),
  mnar = data_sim %>%
    mutate(na = .5 + (1 / 2) * (x2 - 20) + rnorm(n_sim, sd = 2),
           na = logit2prob(na),
           na = as.logical(round(na)),
           x2 = replace(x2, na, NA)) %>%
    select(-na)
)

# complete cases
complete_cases <- data_miss %>%
  map(na.omit) %>%
  map_df(get_miss_stat, .id = "id")

# available cases
available_cases <- data_miss %>%
  map_df(~ .x %>%
    summarize(mu_1 = mean(x1, na.rm = TRUE),
              mu_2 = mean(x2, na.rm = TRUE),
              sigma_1 = var(x1, use = "complete.obs"),
              sigma_2 = var(x2, use = "complete.obs"),
              sigma_12 = cov(., use = "pairwise.complete.obs")[1, 2],
              rho = cor(., use = "pairwise.complete.obs")[1, 2],
              beta_12 = psych::setCor("x2", "x1",
                   data = cov(., use = "pairwise.complete.obs"),
                   n.obs = nrow(na.omit(.))) %>%
                .$beta %>%
                .[[1]],
              beta_21 = psych::setCor("x1", "x2",
                   data = cov(., use = "pairwise.complete.obs"),
                   n.obs = nrow(na.omit(.))) %>%
                .$beta %>%
                .[[1]]
    ), .id = "id")

# mean imputation
mean_imp <- data_miss %>%
  map(~ mutate(.x, x2 = ifelse(is.na(x2), mean(x2, na.rm = TRUE), x2))) %>%
  map_df(get_miss_stat, .id = "id")

# regression imputation
reg_imp <- data_miss %>%
  map(~ .x %>%
        mutate(x2_imp = lm(x2 ~ x1, data = .) %>%
                 predict(., newdata = .x),
               x2 = ifelse(is.na(x2), x2_imp, x2))) %>%
  map_df(get_miss_stat, .id = "id")

sum_stats <- bind_rows(
  `Population parameters` = tibble(
    mu_1 = 10,
    mu_2 = 20,
    sigma_1 = 9,
    sigma_2 = 16,
    sigma_12 = 8,
    rho = .667,
    beta_12 = .5,
    beta_21 = .889),
  `Complete data` = get_miss_stat(data_sim),
  `Complete cases` = complete_cases,
  `Available cases` = available_cases,
  `Mean imputation` = mean_imp,
  `Regression imputation` = reg_imp,
  .id = "method"
) %>%
  mutate(id = ifelse(method == "Population parameters", "Parameter", id),
         id = ifelse(method == "Complete data", "Complete data", id)) %>%
  gather(param, value, -method, -id) %>%
  mutate(param = ifelse(param == "mu_1", "mu[1]", param),
         param = ifelse(param == "mu_2", "mu[2]", param),
         param = ifelse(param == "sigma_1", "sigma[1]^2", param),
         param = ifelse(param == "sigma_2", "sigma[2]^2", param),
         param = ifelse(param == "sigma_12", "sigma[12]", param),
         param = ifelse(param == "beta_12", "beta[12]", param),
         param = ifelse(param == "beta_21", "beta[21]", param)) %>%
  mutate(param = factor(param,
                        levels = c("mu[1]", "mu[2]",
                                   "sigma[1]^2", "sigma[2]^2",
                                   "sigma[12]", "rho",
                                   "beta[12]", "beta[21]")))
```

```{r compare-imputation-plot, echo = FALSE}
sum_stats %>%
  filter(id %in% c("mcar", "mar", "mnar")) %>%
  mutate(id = factor(id, levels = c("mcar", "mar", "mnar"),
                     labels = c("MCAR", "MAR", "MNAR"))) %>%
  ggplot(aes(id, value, color = method, shape = method)) +
  facet_wrap( ~ param, nrow = 2, scales = "free_y",
              labeller = "label_parsed") +
  geom_point() +
  geom_hline(data = filter(sum_stats, id == "Parameter"),
             aes(yintercept = value)) +
  scale_color_brewer(type = "qual", palette = "Dark2", 
                     guide = guide_legend(nrow = 2)) +
  labs(x = NULL,
       y = "Estimated parameter value",
       color = NULL,
       shape = NULL) +
  theme(legend.position = "bottom")
```

---

# Implementing imputation

* `recipes`
* `scikit-learn`

---

# `credit_data`

```{r credit-data}
library(recipes)

credit_data <- credit_data %>%
  as_tibble()
glimpse(credit_data)
```

---

# `credit_data`

```{r credit-data-missmap, dependson = "credit-data"}
# missingness map
Amelia::missmap(as.data.frame(credit_data))
```

---

# Mean imputation

```{r credit-data-sample, dependson = "credit-data"}
set.seed(342)
in_training <- sample(1:nrow(credit_data), 2000)

credit_tr <- credit_data[in_training, ]
credit_te <- credit_data[-in_training, ]
missing_examples <- c(14, 394, 565)
```

```{r credit-data-recipe, dependson = "credit-data-sample"}
rec <- recipe(Price ~ ., data = credit_tr)
```

```{r credit-data-mean, dependson = "credit-data-recipe"}
impute_rec <- rec %>%
  step_meanimpute(Income, Assets, Debt)

imp_models <- prep(impute_rec, training = credit_tr)
imputed_te <- bake(imp_models, new_data = credit_te, everything())

credit_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)

imputed_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)
```

---

# Median imputation

```{r credit-data-median, dependson = "credit-data-recipe"}
impute_rec <- rec %>%
  step_medianimpute(Income, Assets, Debt)

imp_models <- prep(impute_rec, training = credit_tr)

imputed_te <- bake(imp_models, new_data = credit_te, everything())

credit_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)

imputed_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)
```

---

# Modal imputation

```{r credit-data-mode, dependson = "credit-data-recipe"}
impute_rec <- rec %>%
  step_modeimpute(Status, Home, Marital, Job)

imp_models <- prep(impute_rec, training = credit_tr)
imputed_te <- bake(imp_models, new_data = credit_te, everything())

credit_te %>%
  select(-Seniority, -Expenses, -Records) %>%
  slice(missing_examples)

imputed_te %>%
  select(-Seniority, -Expenses, -Records) %>%
  slice(missing_examples)
```

---

# $K$ nearest neighbors imputation

* Uses $K$ nearest neighbors to estimate model with the imputing variable as the outcome of interest, using all the other available variables
* Once $K$ nearest neighbors are found, the mode is used to predict nominal variables and the mean is used for numeric variables

---

# $K$ nearest neighbors imputation

```{r credit-data-knn, dependson = "credit-data-recipe"}
impute_rec <- rec %>%
  step_knnimpute(all_predictors(), neighbors = 5)

imp_models <- prep(impute_rec, training = credit_tr)
imputed_te <- bake(imp_models, new_data = credit_te, everything())

credit_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)

imputed_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)
```

---

# Tree-aggregation imputation

* Use tree-based method to generate imputed values
* Ensemble of trees

---

# Tree bagging imputation

```{r credit-data-tree, dependson = "credit-data-recipe"}
impute_rec <- rec %>%
  step_bagimpute(all_predictors())

imp_models <- prep(impute_rec, training = credit_tr)
imputed_te <- bake(imp_models, new_data = credit_te, everything())

credit_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)

imputed_te %>%
  select(-Seniority, -Marital, -Records) %>%
  slice(missing_examples)
```

---

# Imputation rules of thumb

* For predictive modeling, these methods are typically most utilized
* If the method accepts missing values, no need to impute
* Compare the effect of different imputation strategies on model performance
* Exclude the validation/test set from imputation strategy

---

# Multiple imputation

* Generate multiple imputed datasets
* Bayesian multiple imputation
* Account for uncertainty within and across the datasets

---

# Maximum-likelihood estimation

* Joint PDF for the complete data $\mathbf{X}$
    
    $$\Pr(\mathbf{X}, \theta) = \Pr(\mathbf{X}_{\text{obs}}, \mathbf{X}_{\text{mis}}; \theta)$$
    * $\theta$

* Estimate marginal distribution of observed data

    $$\Pr(\mathbf{X}_\text{obs}; \theta) = \int{\Pr(\mathbf{X}_{\text{obs}}, \mathbf{X}_{\text{mis}}; \theta)} d\mathbf{X}_{\text{mis}}$$

* Directly calculated for MCAR/MAR
* More complex implementation for MNAR

---

# Predictive mean matching

1. For cases with no missing data, estimate a linear regression of $x$ on $z$, producing a set of coefficients $b$
1. Make a random draw from the **posterior predictive distribution** of $b$, producing a new set of coefficients $b*$
1. Using $b*$, generate predicted values for $x$ for all cases, both those with data missing on $x$ and those with data present
1. For each case with missing $x$, identify a set of cases with observed $x$ whose predicted values are close to the predicted value for the case with missing data
1. From among those close cases, randomly choose one and assign its observed value to substitute for the missing value

---

# Inference for individual coefficients

$$\tilde{\beta}_j \equiv \frac{\sum_{l=1}^g B_j^{(l)}}{g}$$

$$\tilde{\se}(\tilde{\beta}_j) = \sqrt{\Var_j^{(W)} + \frac{g + 1}{g} \Var_j^{(B)}}$$

$$\Var_j^{(W)} = \frac{\sum_{l=1}^g \se^2(B_j^{(l)})}{g}$$

$$\Var_j^{(B)} = \frac{\sum_{l=1}^g (B_j^{(l)} - \tilde{B}_j)^2}{g-1}$$

$$\se^2(B_j^{(l)})$$

---

# Practical considerations for MI

* Which variables to include
* Transform variables to approximately normal
* Adjust the imputed data to resemble the original data
* Make sure the imputation model captures relevant features of the data
* $g$ doesn't need to be large

---

# Infant mortality

```{r import-un}
un <- read_delim(here("static", "data", "UnitedNations.txt"), delim = " ")
```

```{r plot-infant-gdp}
ggplot(un, aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  scale_x_continuous(labels = scales::dollar) +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")
```

---

# Infant mortality

.pull-left[

```{r log-log, fig.width = 6}
ggplot(un, aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  scale_x_log10(labels = scales::dollar) +
  scale_y_log10() +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")
```

]

.pull-right[

```{r log-log-regress}
mortal_mod <- lm(log(infantMortality) ~ log(GDPperCapita) +
                   contraception + educationFemale,
                 data = un)
tidy(mortal_mod)
```

]

---

# Infant mortality missingness

```{r miss-pattern}
Amelia::missmap(un)
```

---

# `Amelia`

```{r un-amelia, include = FALSE}
library(Amelia)
un.out <- amelia(as.data.frame(un), m = 5, idvars = c("country", "region"))
```

```{r amelia-result}
glimpse(un.out$imputations)
```

---

# Multiple imputed data

```{r plot-imput}
un.out$imputations %>%
  map(as.data.frame) %>%
  bind_rows(.id = "impute") %>%
  ggplot(aes(GDPperCapita, infantMortality)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  scale_x_continuous(labels = scales::dollar) +
  facet_grid(impute ~ .) +
  labs(x = "GDP per capita (in USD)",
       y = "Infant mortality rate (per 1,000)")
```

---

# Multiple imputed data

```{r amelia-purrr}
models_imp <- tibble(data = un.out$imputations) %>%
  mutate(model = map(data, ~ lm(log(infantMortality) ~ log(GDPperCapita) +
                                  contraception + educationFemale,
                                data = .x)),
         coef = map(model, tidy)) %>%
  unnest(coef, .id = "id")
models_imp
```

---

# Multiple imputed data

```{r mi-meld}
mi.meld.plus <- function(df_tidy){
  # transform data into appropriate matrix shape
  coef.out <- df_tidy %>%
    select(id:estimate) %>%
    spread(term, estimate) %>%
    select(-id)
  
  se.out <- df_tidy %>%
    select(id, term, std.error) %>%
    spread(term, std.error) %>%
    select(-id)
  
  combined.results <- mi.meld(q = coef.out, se = se.out)
  
  tibble(term = colnames(combined.results$q.mi),
         estimate.mi = combined.results$q.mi[1, ],
         std.error.mi = combined.results$se.mi[1, ])
}

# compare results
tidy(mortal_mod) %>%
  left_join(mi.meld.plus(models_imp)) %>%
  select(-statistic, -p.value)
```

---

# Transforming variables

```{r heatmap, warning = FALSE}
GGally::ggpairs(select_if(un, is.numeric))
```

---

# Transforming variables

```{r select-un, warning = FALSE}
un_lite <- un %>%
  select(infantMortality, GDPperCapita, contraception, educationFemale,
         tfr, lifeFemale, economicActivityFemale, illiteracyFemale)

GGally::ggpairs(un_lite)
```

---

# Multiple imputation (redux)

```{r amelia-transform, include = FALSE}
un_lite.out <- amelia(un_lite, m = 5,
                      logs = c("infantMortality", "GDPperCapita"),
                      sqrt = c("tfr"))
```

```{r amelia-trans-mod}
models_trans_imp <- tibble(data = un_lite.out$imputations) %>%
  mutate(model = map(data, ~ lm(log(infantMortality) ~ log(GDPperCapita) +
                                  contraception + educationFemale,
                                data = .x)),
         coef = map(model, tidy)) %>%
  unnest(coef, .id = "id")
# models_trans_imp
# 
# # compare results
# tidy(mortal_mod) %>%
#   left_join(mi.meld.plus(models_trans_imp)) %>%
#   select(-statistic, -p.value)

# cheating on my confidence intervals for this plot
bind_rows(orig = tidy(mortal_mod),
          full_imp = mi.meld.plus(models_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          trans_imp = mi.meld.plus(models_trans_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          .id = "method") %>%
  mutate(method = factor(method, levels = c("orig", "full_imp", "trans_imp"),
                         labels = c("Listwise deletion", "Full imputation",
                                    "Transformed imputation")),
         term = factor(term, levels = c("(Intercept)", "contraception",
                                        "educationFemale", "log(GDPperCapita)"),
                       labels = c("Intercept", "Contraception", "Female education",
                                  "GDP per capita (log)"))) %>%
  ggplot(aes(fct_rev(term), estimate, color = fct_rev(method),
             ymin = estimate - 1.96 * std.error,
             ymax = estimate + 1.96 * std.error)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_pointrange(position = position_dodge(.75)) +
  coord_flip() +
  scale_color_brewer(type = "qual", guide = guide_legend(reverse = TRUE)) +
  labs(title = "Comparing regression results",
       x = NULL,
       y = "Estimated parameter",
       color = NULL) +
  theme(legend.position = "bottom")
```

---

# Multiple imputation (redux)

```{r amelia-trans-mod-lite}
bind_rows(orig = tidy(mortal_mod),
          full_imp = mi.meld.plus(models_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          trans_imp = mi.meld.plus(models_trans_imp) %>%
            rename(estimate = estimate.mi,
                   std.error = std.error.mi),
          .id = "method") %>%
  mutate(method = factor(method, levels = c("orig", "full_imp", "trans_imp"),
                         labels = c("Listwise deletion", "Full imputation",
                                    "Transformed imputation")),
         term = factor(term, levels = c("(Intercept)", "contraception",
                                        "educationFemale", "log(GDPperCapita)"),
                       labels = c("Intercept", "Contraception", "Female education",
                                  "GDP per capita (log)"))) %>%
  filter(term != "Intercept") %>%
  ggplot(aes(fct_rev(term), estimate, color = fct_rev(method),
             ymin = estimate - 1.96 * std.error,
             ymax = estimate + 1.96 * std.error)) +
  geom_hline(yintercept = 0, linetype = 2) +
  geom_pointrange(position = position_dodge(.75)) +
  coord_flip() +
  scale_color_brewer(type = "qual", guide = guide_legend(reverse = TRUE)) +
  labs(title = "Comparing regression results",
       subtitle = "Omitting intercept from plot",
       x = NULL,
       y = "Estimated parameter",
       color = NULL) +
  theme(legend.position = "bottom")
```
