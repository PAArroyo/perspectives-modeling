---
title: "Boosting"
date: 2019-02-23T13:30:00  # Schedule page publish date.
draft: false
type: "talk"

output:
  blogdown::html_page:
    toc: false
    number_sections: false

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
time_start: 2019-02-27T13:30:00
time_end: 2019-02-27T15:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors: []

# Abstract and optional shortened version.
abstract: ""
abstract_short: "Boosting and additive tree models, including different implementations of boosting algorithms."

# Location of event.
location: "Room 247, Saieh Hall for Economics, Chicago, IL"

# Is this a selected talk? (true/false)
selected: false

# Tags (optional).
#   Set `tags: []` for no tags, or use the form `tags: ["A Tag", "Another Tag"]` for one or more tags.
tags: []

# Links (optional).
url_pdf: ""
url_slides: ""
url_video: ""
url_code: ""

# Does the content use math formatting?
math: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Overview

* Define random forests
* Compare bagging and random forest algorithms
* Define boosting
* Apply gradient boosting to decision trees
* Implement boosting models and compare performance to other tree-based methods

## Before class

* ISL ch 8.2.3
* ESL ch 10

## Slides and class materials

```{r slides}
knitr::include_url("/slides/rf-boosting.html", height = "505px")
```

* [Random forests](/notes/random-forest/)

### Additional readings

* [Random forests](http://uc-r.github.io/random_forests)
* [Gradient boosting machines](http://uc-r.github.io/gbm_regression)

* [Chapter 5 in *Python Data Science Handbook*](http://proquestcombo.safaribooksonline.com.proxy.uchicago.edu/book/programming/python/9781491912126) - covers hyperparameter tuning with `scikit-learn`
* [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/)

## What you need to do

