---
title: "Homework 05: Interpreting Machine Learning Models"
date: 2019-02-05T13:30:00-06:00  # Schedule page publish date

draft: false
type: post

output:
  blogdown::html_page:
    number_sections: false

summary: "Practice implementing global and local interpretation methods."
---

<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<div id="TOC">
<ul>
<li><a href="#fork-the-hw05-repository">Fork the <code>hw05</code> repository</a></li>
<li><a href="#submission-format">Submission format</a></li>
<li><a href="#predicting-attitudes-towards-racist-college-professors">Predicting attitudes towards racist college professors</a><ul>
<li><a href="#train-a-series-of-models-3-points">Train a series of models (3 points)</a></li>
<li><a href="#evaluate-their-performance-2-points">Evaluate their performance (2 points)</a></li>
<li><a href="#interpret-and-explain-the-model-5-points">Interpret and explain the model (5 points)</a><ul>
<li><a href="#global-explanations">Global explanations</a></li>
<li><a href="#local-interpretation">Local interpretation</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<p>Due by 11:59pm February 11th.</p>
<div id="fork-the-hw05-repository" class="section level1">
<h1>Fork the <code>hw05</code> repository</h1>
<p>Go <a href="https://github.com/css-model/hw05">here</a> to fork the repo for homework 05.</p>
</div>
<div id="submission-format" class="section level1">
<h1>Submission format</h1>
<p>For each of the following questions, produce brief written answers and/or the required graphs. Your responses must be readable on GitHub (i.e. we should not have to fork your repo to view the responses). The document should be <strong>reproducible</strong>. This means you need to commit and push all your code, output, and written text to complete the exercises. If necessary, I should be able to clone your repository and run all the code without any errors. Recommended document formats are Jupyter Notebook (<code>.ipynb</code>) or R Markdown (<code>.Rmd</code>) rendered as <code>pdf_document</code>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
</div>
<div id="predicting-attitudes-towards-racist-college-professors" class="section level1">
<h1>Predicting attitudes towards racist college professors</h1>
<p>The <a href="http://gss.norc.org/">General Social Survey</a> is a biannual survey of the American public.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<blockquote>
<p><a href="http://gss.norc.org/About-The-GSS">The GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviors, and attributes. Hundreds of trends have been tracked since 1972. In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years. The GSS contains a standard core of demographic, behavioral, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.</a></p>
</blockquote>
<p>In this problem set, you are going to predict attitudes towards racist college professors. Specifically, each respondent was asked “Should a person who believes that Blacks are genetically inferior be allowed to teach in a college or university?” Given the kerfuffle over Richard J. Herrnstein and Charles Murray’s <a href="https://en.wikipedia.org/wiki/The_Bell_Curve"><em>The Bell Curve</em></a> and the ostracization of Nobel Prize laureate <a href="https://en.wikipedia.org/wiki/James_Watson">James Watson</a> over his controversial views on race and intelligence, this analysis will provide further insight into the public debate over this issue.</p>
<p><code>gss_*.csv</code> contain a selection of variables from the 2012 GSS. The outcome of interest <code>colrac</code> is a binary variable coded as either <code>ALLOWED</code> or <code>NOT ALLOWED</code>. Documentation for the other predictors (if the variable is not clearly coded) can be viewed <a href="https://gssdataexplorer.norc.org/variables/vfilter">here</a>. Some data pre-processing has been done in advance for you to ease your model fitting:</p>
<ol style="list-style-type: decimal">
<li>Missing values have been imputed.</li>
<li>Categorical variables with low-frequency classes had those classes collapsed into an “other” category.</li>
<li>Nominal variables with more than two classes have been converted to dummy variables.</li>
<li>Remaining categorical variables have been converted to integer values, stripping their original labels.</li>
</ol>
<p>Your mission is to construct a series of statistical/machine learning models to accurately predict an individual’s attitude towards permitting individuals who view blacks to be racially inferior to teach in a college classroom. The goals of the exercise are two-fold:</p>
<ol style="list-style-type: decimal">
<li>Build a highly accurate model</li>
<li>Interpret and explain the results of the best model in a human meaningful way (i.e. global and local explanations)</li>
</ol>
<div id="train-a-series-of-models-3-points" class="section level2">
<h2>Train a series of models (3 points)</h2>
<p>Using the observations in <code>gss_train.csv</code>:</p>
<ol style="list-style-type: decimal">
<li>Use <span class="math inline">\(10\)</span>-fold cross-validation to partition the training set into training and validation sets.</li>
<li>Fit the following statistical models using <span class="math inline">\(10\)</span>-fold cross-validation:
<ol style="list-style-type: lower-alpha">
<li>Logistic regression</li>
<li>Linear discriminant analysis</li>
<li>Quadratic discriminant analysis</li>
<li>Naive Bayes</li>
<li><span class="math inline">\(K\)</span>-nearest neighbors</li>
</ol></li>
</ol>
<ul>
<li>Use all available predictors for each model.</li>
<li>I am not specifying hyperparameter settings for any of the modeling strategies. I leave it to you to determine the optimal settings. However, you need to briefly justify how you selected your hyperparameter settings. Don’t just arbitrarily select values, do some tuning.</li>
</ul>
</div>
<div id="evaluate-their-performance-2-points" class="section level2">
<h2>Evaluate their performance (2 points)</h2>
<ol style="list-style-type: decimal">
<li>Evaluate each model’s performance using the validation set. Select the best model based on the validation set performance and whatever metrics you feel are important (e.g. error rate, proportional reduction in error, ROC curve, area under the curve).</li>
<li>Once you select the best model, calculate your final estimate of the test error rate using the test set (<code>gss_test.csv</code>). To do this, take your best model and re-fit it using the entire training set (i.e. no cross-validation). Then calculate your performance metrics using the original test set.</li>
</ol>
</div>
<div id="interpret-and-explain-the-model-5-points" class="section level2">
<h2>Interpret and explain the model (5 points)</h2>
<div id="global-explanations" class="section level3">
<h3>Global explanations</h3>
<p>Using the naive Bayes model, explain how the model works globally using the following techniques:</p>
<ol style="list-style-type: decimal">
<li>Feature importance</li>
<li>Feature interactions</li>
<li>Partial dependence plots (PDPs) and individual conditional expectation (ICE) plots
<ul>
<li>Generate plots for the five most important variables as determined by the feature importance scores</li>
</ul></li>
<li>Global surrogate</li>
</ol>
<p>If you have not already, re-estimate the model using all of the training set observations in <code>gss_train.csv</code> and use that model and the training data to generate the global explanations.</p>
<ul>
<li>For those using Python, I recommend using the <a href="https://github.com/datascienceinc/Skater"><code>Skater</code></a> package
<ul>
<li>Currently supports PDPs and permutation-based feature importance</li>
<li>I don’t see support for permutation-based feature interactions. If you cannot find an existing package which implements this method, you can omit it from your analysis.</li>
<li>Global surrogate model can be generated manually with ease</li>
</ul></li>
<li>For those using R, I recommend using the <a href="https://cran.r-project.org/web/packages/iml/index.html"><code>iml</code></a> package</li>
</ul>
</div>
<div id="local-interpretation" class="section level3">
<h3>Local interpretation</h3>
<p>Using your naive Bayes model, explain how the model works locally for the five held-out observations in <code>gss_local.csv</code> using the <code>lime</code> procedure. First, generate the local surrogate model using the default hyperparameters for <code>lime</code> and interpret the surrogate model for each observation. Second, generate the local surrogate model by tuning the hyperparameters for <code>lime</code> and interpret the surrogate model for each observation. How does your interpretation change, if at all?</p>
<ul>
<li><a href="https://github.com/marcotcr/lime">Implementation of Lime in Python</a></li>
<li><a href="http://uc-r.github.io/lime">Implementation of LIME in R</a></li>
</ul>
<div id="support-for-e1071naivebayes" class="section level5">
<h5>Support for <code>e1071::naiveBayes()</code></h5>
<p>If you use R and the <code>naiveBayes</code> function from <code>e1071</code>, include the following code to allow <code>lime</code> to accept an <code>naiveBayes</code> object for the <code>explainer()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate model support in lime</span>
model_type.naiveBayes &lt;-<span class="st"> </span><span class="cf">function</span>(x, ...){
  <span class="kw">return</span>(<span class="st">&quot;classification&quot;</span>)
}

predict_model.naiveBayes &lt;-<span class="st"> </span><span class="cf">function</span>(x, newdata, ...){
  pred &lt;-<span class="st"> </span><span class="kw">predict</span>(x, newdata, <span class="dt">type =</span> <span class="st">&quot;raw&quot;</span>)
  <span class="kw">return</span>(<span class="kw">as.data.frame</span>(pred))
}</code></pre></div>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><code>html_document</code> cannot be viewed directly on GitHub.com, and GitHub does not properly render mathematical equations in <code>.md</code> documents 😿<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Conducted by NORC at the University of Chicago.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
