---
title: Local regression
date: 2019-02-20T13:30:00-06:00  # Schedule page publish date.
    
draft: false
type: docs

bibliography: [../../static/bib/sources.bib]
csl: [../../static/bib/apa.csl]
link-citations: true

menu:
  notes:
    parent: Moving beyond linearity
    weight: 3
---

<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<div id="TOC">
<ul>
<li><a href="#kernel-functions"><span class="toc-section-number">1</span> Kernel functions</a><ul>
<li><a href="#examples-of-kernel-functions"><span class="toc-section-number">1.1</span> Examples of kernel functions</a></li>
</ul></li>
<li><a href="#kernel-smoothing"><span class="toc-section-number">2</span> Kernel smoothing</a><ul>
<li><a href="#tuning-parameters"><span class="toc-section-number">2.1</span> Tuning parameters</a></li>
</ul></li>
<li><a href="#local-regression"><span class="toc-section-number">3</span> Local regression</a><ul>
<li><a href="#local-linear-regression"><span class="toc-section-number">3.1</span> Local linear regression</a></li>
<li><a href="#local-polynomial-regression"><span class="toc-section-number">3.2</span> Local polynomial regression</a></li>
<li><a href="#higher-dimensional-local-regression"><span class="toc-section-number">3.3</span> Higher dimensional local regression</a></li>
</ul></li>
<li><a href="#session-info"><span class="toc-section-number">4</span> Session Info</a></li>
<li><a href="#references"><span class="toc-section-number">5</span> References</a></li>
</ul>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(tidymodels)
<span class="kw">library</span>(rcfss)
<span class="kw">library</span>(titanic)
<span class="kw">library</span>(knitr)
<span class="kw">library</span>(splines)
<span class="kw">library</span>(ISLR)
<span class="kw">library</span>(lattice)
<span class="kw">library</span>(gam)
<span class="kw">library</span>(here)
<span class="kw">library</span>(patchwork)
<span class="kw">library</span>(margins)
<span class="kw">library</span>(gganimate)

<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="kw">theme_set</span>(<span class="kw">theme_minimal</span>())</code></pre></div>
<div id="kernel-functions" class="section level1">
<h1><span class="header-section-number">1</span> Kernel functions</h1>
<p>A <strong>kernel</strong> is a weighting function used for non-parametric estimation techniques. Formally, it is a non-negative real-valued integrable function <span class="math inline">\(K\)</span>. For our purposes, we impose two additional requirements:</p>
<ul>
<li><p>Normalization</p>
<p><span class="math display">\[\int_{-\infty}^{+\infty} K(u) du = 1\]</span></p>
<ul>
<li>This ensures when we apply the kernel function to non-parametric estimation, the result is a probability density function (PDF).</li>
</ul></li>
<li>Symmetry - <span class="math inline">\(K(-u) = K(u)\)</span> for all values of <span class="math inline">\(u\)</span>
<ul>
<li>Ensures the average of the resulting distribution is equal to that of the sample used.</li>
</ul></li>
</ul>
<div id="examples-of-kernel-functions" class="section level2">
<h2><span class="header-section-number">1.1</span> Examples of kernel functions</h2>
<div id="gaussian-kernel" class="section level5">
<h5><span class="header-section-number">1.1.0.0.1</span> Gaussian kernel</h5>
<p><span class="math display">\[K(u) = \frac{1}{\sqrt{2 \pi}}e^{-\frac{1}{2} u^2}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1000</span>)

<span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Gaussian (normal) kernel&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/gaussian-1.png" width="672" /></p>
</div>
<div id="rectangular-uniform-kernel" class="section level5">
<h5><span class="header-section-number">1.1.0.0.2</span> Rectangular (uniform) kernel</h5>
<p><span class="math display">\[K(u) = \frac{1}{2} \mathbf{1}_{\{ |u| \leq 1 \} }\]</span></p>
<p>where <span class="math inline">\(\mathbf{1}_{\{ |z| \leq 1 \} }\)</span> is an indicator function that takes on the value of 1 if the condition is true (<span class="math inline">\(|z| \leq 1\)</span>) or 0 if the condition is false.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1000</span>, <span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)
x_lines &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>x, <span class="op">~</span>y, <span class="op">~</span>xend, <span class="op">~</span>yend,
  <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, .<span class="dv">5</span>,
  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">5</span>
)

<span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dunif, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">min =</span> <span class="op">-</span><span class="dv">1</span>), <span class="dt">geom =</span> <span class="st">&quot;step&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="co"># geom_segment(data = x_lines, aes(x = x, y = y, xend = xend, yend = yend)) +</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Rectangular kernel&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/uniform-1.png" width="672" /></p>
</div>
<div id="triangular-kernel" class="section level5">
<h5><span class="header-section-number">1.1.0.0.3</span> Triangular kernel</h5>
<p><span class="math display">\[K(u) = (1 - |z|) \mathbf{1}_{\{ |u| \leq 1 \} }\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">triangular &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">abs</span>(x)) <span class="op">*</span><span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">abs</span>(x) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>)
}

<span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> triangular) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Triangular kernel&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/triangular-1.png" width="672" /></p>
</div>
<div id="tricube-kernel" class="section level5">
<h5><span class="header-section-number">1.1.0.0.4</span> Tricube kernel</h5>
<p><span class="math display">\[K(u) = \frac{70}{81} (1 - |u|^3)^3 \mathbf{1}_{\{ |u| \leq 1 \} }\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tricube &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  (<span class="dv">70</span> <span class="op">/</span><span class="st"> </span><span class="dv">81</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">abs</span>(x)<span class="op">^</span><span class="dv">3</span>)<span class="op">^</span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">abs</span>(x) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>)
}

<span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> tricube) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Tricube kernel&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/tricube-1.png" width="672" /></p>
</div>
<div id="epanechnikov-kernel" class="section level5">
<h5><span class="header-section-number">1.1.0.0.5</span> Epanechnikov kernel</h5>
<p><span class="math display">\[K(u) = \frac{3}{4} (1 - u^2) \mathbf{1}_{\{ |u| \leq 1 \} }\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">epanechnikov &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  (<span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>x<span class="op">^</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">abs</span>(x) <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>)
}

<span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> epanechnikov) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Epanechnikov kernel&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/epanechnikov-1.png" width="672" /></p>
</div>
<div id="comparison-of-kernels" class="section level5">
<h5><span class="header-section-number">1.1.0.0.6</span> Comparison of kernels</h5>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(x, <span class="dt">geom =</span> <span class="st">&quot;blank&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Gaussian&quot;</span>), <span class="dt">fun =</span> dnorm) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Epanechnikov&quot;</span>), <span class="dt">fun =</span> epanechnikov) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Rectangular&quot;</span>), <span class="dt">fun =</span> dunif,
                <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">min =</span> <span class="op">-</span><span class="dv">1</span>), <span class="dt">geom =</span> <span class="st">&quot;step&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Triangular&quot;</span>), <span class="dt">fun =</span> triangular) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Tricube&quot;</span>), <span class="dt">fun =</span> tricube) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>,
       <span class="dt">color =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.04</span>, <span class="dv">1</span>),
        <span class="dt">legend.justification =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),
        <span class="dt">legend.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>))</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/kernels-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="kernel-smoothing" class="section level1">
<h1><span class="header-section-number">2</span> Kernel smoothing</h1>
<p>Kernel smoothing is a method for estimating the regression function <span class="math inline">\(f(X)\)</span> over the domain <span class="math inline">\(\Re^p\)</span> by fitting a different but simple model separately at each query point <span class="math inline">\(x_0\)</span>. This is done by using only observations closed to the target point <span class="math inline">\(x_0\)</span> to fit the model, but also in a way such that the resulting estimated function <span class="math inline">\(f(X)\)</span> is <strong>smooth</strong> in <span class="math inline">\(\Re^p\)</span>. We use a weighting function, aka the <strong>kernel</strong> <span class="math inline">\(K_\lambda (x_o, x_i)\)</span>, to assign a weight to <span class="math inline">\(x_i\)</span> based on its distance from <span class="math inline">\(x_0\)</span>. The kernels are indexed by a parameter <span class="math inline">\(\lambda\)</span> which determines the the width of the local neighborhood used to include observations for each <span class="math inline">\(x_0\)</span>.</p>
<p>Kernel smoothing is strongly related to <a href="/notes/nearest-neighbors/"><span class="math inline">\(k\)</span>-nearest neighbors</a>,</p>
<p><span class="math display">\[\hat{f}(x) = \text{Ave} (y_i | x_i \in N_k(x))\]</span></p>
<p>as an estimation of the regression function <span class="math inline">\({\mathrm{E}}(Y | X = x)\)</span>. <span class="math inline">\(N_k(x)\)</span> is the set of <span class="math inline">\(k\)</span> points nearest to <span class="math inline">\(x\)</span> in squared distance. Consider this method applied to some simulated data points:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kernel_sim &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">100</span>),
  <span class="dt">y =</span> <span class="kw">sin</span>(<span class="dv">4</span> <span class="op">*</span><span class="st"> </span>x) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)
)

kernel_test &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">by =</span> .<span class="dv">001</span>)
)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kernel_test &lt;-<span class="st"> </span>kernel_test <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> FNN<span class="op">::</span><span class="kw">knn.reg</span>(<span class="dt">train =</span> <span class="kw">select</span>(kernel_sim, x),
                          <span class="dt">test =</span> kernel_test,
                          <span class="dt">y =</span> kernel_sim<span class="op">$</span>y,
                          <span class="dt">k =</span> <span class="dv">30</span>)<span class="op">$</span>pred)

<span class="kw">ggplot</span>(kernel_sim, <span class="kw">aes</span>(x, y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> <span class="cf">function</span>(x) <span class="kw">sin</span>(<span class="dv">4</span> <span class="op">*</span><span class="st"> </span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> kernel_test, <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;30-nearest neighbor kernel&quot;</span>,
       <span class="dt">x =</span> <span class="kw">expression</span>(x[<span class="dv">0</span>]),
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/sim-naive-1.png" width="672" /></p>
<p>The resulting line is bumpy, since the fit at each <span class="math inline">\(x_0\)</span> is an average of the local neighborhood and the resulting function <span class="math inline">\(\hat{f}(x)\)</span> is discontinuous in <span class="math inline">\(x\)</span>. The average changes in a discrete way, leading to the discontinuties.</p>
<p>Kernel smoothing allows us to change the weights of each of the observations in the neighborhood: rather than weighting them equally, we assign weights based on the distance of <span class="math inline">\(x_i\)</span> from <span class="math inline">\(x_0\)</span>. A popular technique that implements this is called the <strong>Nadaraya-Watson kernel-weighted average</strong>:</p>
<p><span class="math display">\[\hat{f}(x_0) = \frac{\sum_{i=1}^N K_\lambda(x_0, x_i)y_i}{\sum_{i=1}^N K_\lambda (x_0, x_i)}\]</span></p>
<p><span class="math inline">\(K_\lambda(x_0, x_i)\)</span> is the <strong>Epanechnikov</strong> quadratic kernel (as seen earlier):</p>
<p><span class="math display">\[K_\lambda(x_0, x_i) = D \left( \frac{| x - x_0 |}{\lambda} \right)\]</span></p>
<p>with</p>
<p><span class="math display">\[
D(t) = \begin{cases}
\frac{3}{4} (1 - t^2) &amp; \text{if } |t| \leq 1 \\
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>Applied to the dataset, we get a smoothing line that looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(kernel_sim, <span class="kw">aes</span>(x, y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> <span class="cf">function</span>(x) <span class="kw">sin</span>(<span class="dv">4</span> <span class="op">*</span><span class="st"> </span>x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> <span class="kw">as_tibble</span>(<span class="kw">ksmooth</span>(kernel_sim<span class="op">$</span>x,
                                     kernel_sim<span class="op">$</span>y,
                                     <span class="dt">kernel =</span> <span class="st">&quot;normal&quot;</span>,
                                     <span class="dt">bandwidth =</span> <span class="fl">0.2</span>,
                                     <span class="dt">n.points =</span> <span class="dv">500</span>)),
            <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Epanechnikov kernel&quot;</span>,
       <span class="dt">x =</span> <span class="kw">expression</span>(x[<span class="dv">0</span>]),
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/sim-epanechnikov-1.png" width="672" /></p>
<p>As observations move into the neighborhood, they are gradually upweighted based on the their distance to <span class="math inline">\(x_0\)</span> and the specific kernel function.</p>
<p>Here, <span class="math inline">\(\lambda\)</span> is a constant value that defines the neighborhood - the interval is the same width regardless of <span class="math inline">\(x_0\)</span>. In <span class="math inline">\(k\)</span>-nearest neighbors, that interval changes width depending on the distance to the closest neighbors. To make it adaptive, we can reexpress <span class="math inline">\(K_\lambda(x_0, x_i)\)</span> as</p>
<p><span class="math display">\[K_\lambda(x_0, x_i) = D \left( \frac{| x - x_0 |}{h_\lambda (x_0)} \right)\]</span></p>
<p>For the Epanechnikov quadratic kernel, <span class="math inline">\(h_\lambda(x_0)\)</span> is a constant value. For other kernels, this value may itself be a function of <span class="math inline">\(x_0\)</span>.</p>
<div id="tuning-parameters" class="section level2">
<h2><span class="header-section-number">2.1</span> Tuning parameters</h2>
<p>For kernel smoothing, there are two major considerations:</p>
<ol style="list-style-type: decimal">
<li>Choice of kernel function - which kernel should we use?</li>
<li>Bandwidth - what should be the value for <span class="math inline">\(\lambda\)</span>?</li>
</ol>
<p>Consider a truly one-dimensional problem. Here, we have a dataset of infant mortality per country.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">infant &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">here</span>(<span class="st">&quot;static&quot;</span>, <span class="st">&quot;data&quot;</span>, <span class="st">&quot;infant.csv&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># remove non-countries</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">is.na</span>(<span class="st">`</span><span class="dt">Value Footnotes</span><span class="st">`</span>) <span class="op">|</span><span class="st"> `</span><span class="dt">Value Footnotes</span><span class="st">`</span> <span class="op">!=</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="st">`</span><span class="dt">Country or Area</span><span class="st">`</span>, Year, Value) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">country =</span> <span class="st">`</span><span class="dt">Country or Area</span><span class="st">`</span>,
         <span class="dt">year =</span> Year,
         <span class="dt">mortal =</span> Value)</code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   `Country or Area` = col_character(),
##   Subgroup = col_character(),
##   Year = col_double(),
##   Source = col_character(),
##   Unit = col_character(),
##   Value = col_double(),
##   `Value Footnotes` = col_double()
## )</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(infant, <span class="kw">aes</span>(mortal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Infant mortality rate for 195 nations&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Infant mortality rate (per 1,000)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Frequency&quot;</span>)</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/notes/local-regression_files/figure-html/infant-1.png" width="672" /></p>
<p>Say we want to use kernel smoothing to visualize this distribution using a continuous, rather than a discrete, function. How does the choice of kernel function influence the appearance of the distribution?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(infant, <span class="kw">aes</span>(mortal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Gaussian&quot;</span>), <span class="dt">kernel =</span> <span class="st">&quot;gaussian&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Epanechnikov&quot;</span>), <span class="dt">kernel =</span> <span class="st">&quot;epanechnikov&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Rectangular&quot;</span>), <span class="dt">kernel =</span> <span class="st">&quot;rectangular&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Triangular&quot;</span>), <span class="dt">kernel =</span> <span class="st">&quot;triangular&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Tricube&quot;</span>), <span class="dt">kernel =</span> <span class="st">&quot;tricube&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>, <span class="dt">palette =</span> <span class="st">&quot;Paired&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Density estimators of infant mortality rate for 195 nations&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Infant mortality rate (per 1,000)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>,
       <span class="dt">color =</span> <span class="st">&quot;Kernel&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(<span class="fl">0.96</span>, <span class="dv">1</span>),
        <span class="dt">legend.justification =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
        <span class="dt">legend.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>))</code></pre></div>
<pre><code>## Warning: Computation failed in `stat_density()`:
## &#39;arg&#39; should be one of &quot;gaussian&quot;, &quot;epanechnikov&quot;, &quot;rectangular&quot;, &quot;triangular&quot;, &quot;biweight&quot;, &quot;cosine&quot;, &quot;optcosine&quot;</code></pre>
<p><img src="/notes/local-regression_files/figure-html/infant-kernels-1.png" width="672" /></p>
<p>Clearly the selection of an appropriate kernel matters to this problem. Typically selected kernels are Epanechnikov, tricube, and Gaussian.</p>
<p>Once you select a kernel, you also need to select <span class="math inline">\(\lambda\)</span>. Take the infant mortality data and the Epanechnikov kernel. How does varying <span class="math inline">\(\lambda\)</span> influence the resulting smoothing line?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kernel_bandwidth &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">bandwidth =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">15</span>, <span class="dt">by =</span> .<span class="dv">1</span>)
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(bandwidth, <span class="op">~</span><span class="st"> </span><span class="kw">density</span>(<span class="dt">x =</span> infant<span class="op">$</span>mortal, <span class="dt">bw =</span> .x, <span class="dt">kernel =</span> <span class="st">&quot;epanechnikov&quot;</span>)),
         <span class="dt">pred =</span> <span class="kw">map</span>(model, <span class="op">~</span><span class="st"> </span><span class="kw">tibble</span>(<span class="dt">x =</span> .x<span class="op">$</span>x,
                                    <span class="dt">y =</span> .x<span class="op">$</span>y))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest</span>(pred) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">group =</span> bandwidth)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlim</span>(<span class="dv">0</span>, <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Epanechnikov kernel&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Bandwidth = {closest_state}&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Infant mortality rate (per 1,000)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">transition_states</span>(bandwidth,
                    <span class="dt">transition_length =</span> .<span class="dv">05</span>,
                    <span class="dt">state_length =</span> .<span class="dv">05</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ease_aes</span>(<span class="st">&quot;cubic-in-out&quot;</span>)

<span class="kw">animate</span>(kernel_bandwidth, <span class="dt">nframes =</span> <span class="kw">length</span>(<span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">15</span>, <span class="dt">by =</span> .<span class="dv">1</span>)) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)</code></pre></div>
<pre><code>## Warning: Removed 5 rows containing missing values (geom_path).

## Warning: Removed 5 rows containing missing values (geom_path).

## Warning: Removed 5 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 6 rows containing missing values (geom_path).

## Warning: Removed 6 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 7 rows containing missing values (geom_path).

## Warning: Removed 7 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 8 rows containing missing values (geom_path).

## Warning: Removed 8 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 9 rows containing missing values (geom_path).

## Warning: Removed 9 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 11 rows containing missing values (geom_path).

## Warning: Removed 11 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 12 rows containing missing values (geom_path).

## Warning: Removed 12 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 13 rows containing missing values (geom_path).

## Warning: Removed 13 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 14 rows containing missing values (geom_path).

## Warning: Removed 14 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 15 rows containing missing values (geom_path).

## Warning: Removed 15 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 16 rows containing missing values (geom_path).

## Warning: Removed 16 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 17 rows containing missing values (geom_path).

## Warning: Removed 17 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 19 rows containing missing values (geom_path).

## Warning: Removed 19 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 20 rows containing missing values (geom_path).

## Warning: Removed 20 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 21 rows containing missing values (geom_path).

## Warning: Removed 21 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 22 rows containing missing values (geom_path).

## Warning: Removed 22 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 23 rows containing missing values (geom_path).

## Warning: Removed 23 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 24 rows containing missing values (geom_path).

## Warning: Removed 24 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 25 rows containing missing values (geom_path).

## Warning: Removed 25 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 26 rows containing missing values (geom_path).

## Warning: Removed 26 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 27 rows containing missing values (geom_path).

## Warning: Removed 27 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 28 rows containing missing values (geom_path).

## Warning: Removed 28 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 29 rows containing missing values (geom_path).

## Warning: Removed 29 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 30 rows containing missing values (geom_path).

## Warning: Removed 30 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 31 rows containing missing values (geom_path).

## Warning: Removed 31 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 32 rows containing missing values (geom_path).

## Warning: Removed 32 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 33 rows containing missing values (geom_path).

## Warning: Removed 33 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 34 rows containing missing values (geom_path).

## Warning: Removed 34 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 35 rows containing missing values (geom_path).

## Warning: Removed 35 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 36 rows containing missing values (geom_path).

## Warning: Removed 36 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 37 rows containing missing values (geom_path).

## Warning: Removed 37 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 38 rows containing missing values (geom_path).

## Warning: Removed 38 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 39 rows containing missing values (geom_path).

## Warning: Removed 39 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 40 rows containing missing values (geom_path).

## Warning: Removed 40 rows containing missing values (geom_path).

## Warning: Removed 40 rows containing missing values (geom_path).

## Warning: Removed 40 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 41 rows containing missing values (geom_path).

## Warning: Removed 41 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 42 rows containing missing values (geom_path).

## Warning: Removed 42 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 43 rows containing missing values (geom_path).

## Warning: Removed 43 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 44 rows containing missing values (geom_path).

## Warning: Removed 44 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 45 rows containing missing values (geom_path).

## Warning: Removed 45 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 46 rows containing missing values (geom_path).

## Warning: Removed 46 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 47 rows containing missing values (geom_path).

## Warning: Removed 47 rows containing missing values (geom_path).

## Warning: Removed 47 rows containing missing values (geom_path).

## Warning: Removed 47 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 48 rows containing missing values (geom_path).

## Warning: Removed 48 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 49 rows containing missing values (geom_path).

## Warning: Removed 49 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 50 rows containing missing values (geom_path).

## Warning: Removed 50 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 51 rows containing missing values (geom_path).

## Warning: Removed 51 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 52 rows containing missing values (geom_path).

## Warning: Removed 52 rows containing missing values (geom_path).

## Warning: Removed 52 rows containing missing values (geom_path).

## Warning: Removed 52 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 53 rows containing missing values (geom_path).

## Warning: Removed 53 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 54 rows containing missing values (geom_path).

## Warning: Removed 54 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 55 rows containing missing values (geom_path).

## Warning: Removed 55 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 56 rows containing missing values (geom_path).

## Warning: Removed 56 rows containing missing values (geom_path).

## Warning: Removed 56 rows containing missing values (geom_path).

## Warning: Removed 56 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 57 rows containing missing values (geom_path).

## Warning: Removed 57 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 58 rows containing missing values (geom_path).

## Warning: Removed 58 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 59 rows containing missing values (geom_path).

## Warning: Removed 59 rows containing missing values (geom_path).

## Warning: Removed 59 rows containing missing values (geom_path).

## Warning: Removed 59 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 60 rows containing missing values (geom_path).

## Warning: Removed 60 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 61 rows containing missing values (geom_path).

## Warning: Removed 61 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 62 rows containing missing values (geom_path).

## Warning: Removed 62 rows containing missing values (geom_path).

## Warning: Removed 62 rows containing missing values (geom_path).

## Warning: Removed 62 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 63 rows containing missing values (geom_path).

## Warning: Removed 63 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 64 rows containing missing values (geom_path).

## Warning: Removed 64 rows containing missing values (geom_path).

## Warning: Removed 64 rows containing missing values (geom_path).

## Warning: Removed 64 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 65 rows containing missing values (geom_path).

## Warning: Removed 65 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 66 rows containing missing values (geom_path).

## Warning: Removed 66 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 67 rows containing missing values (geom_path).

## Warning: Removed 67 rows containing missing values (geom_path).

## Warning: Removed 67 rows containing missing values (geom_path).

## Warning: Removed 67 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 68 rows containing missing values (geom_path).

## Warning: Removed 68 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 69 rows containing missing values (geom_path).

## Warning: Removed 69 rows containing missing values (geom_path).

## Warning: Removed 69 rows containing missing values (geom_path).

## Warning: Removed 69 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 70 rows containing missing values (geom_path).

## Warning: Removed 70 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 71 rows containing missing values (geom_path).

## Warning: Removed 71 rows containing missing values (geom_path).

## Warning: Removed 71 rows containing missing values (geom_path).

## Warning: Removed 71 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 72 rows containing missing values (geom_path).

## Warning: Removed 72 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 73 rows containing missing values (geom_path).

## Warning: Removed 73 rows containing missing values (geom_path).

## Warning: Removed 73 rows containing missing values (geom_path).

## Warning: Removed 73 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 74 rows containing missing values (geom_path).

## Warning: Removed 74 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 75 rows containing missing values (geom_path).

## Warning: Removed 75 rows containing missing values (geom_path).

## Warning: Removed 75 rows containing missing values (geom_path).

## Warning: Removed 75 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 76 rows containing missing values (geom_path).

## Warning: Removed 76 rows containing missing values (geom_path).

## Warning: Removed 76 rows containing missing values (geom_path).

## Warning: Removed 76 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 77 rows containing missing values (geom_path).

## Warning: Removed 77 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 78 rows containing missing values (geom_path).

## Warning: Removed 78 rows containing missing values (geom_path).

## Warning: Removed 78 rows containing missing values (geom_path).

## Warning: Removed 78 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 79 rows containing missing values (geom_path).

## Warning: Removed 79 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 80 rows containing missing values (geom_path).

## Warning: Removed 80 rows containing missing values (geom_path).

## Warning: Removed 80 rows containing missing values (geom_path).

## Warning: Removed 80 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 81 rows containing missing values (geom_path).

## Warning: Removed 81 rows containing missing values (geom_path).

## Warning: Removed 81 rows containing missing values (geom_path).

## Warning: Removed 81 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 82 rows containing missing values (geom_path).

## Warning: Removed 82 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 83 rows containing missing values (geom_path).

## Warning: Removed 83 rows containing missing values (geom_path).

## Warning: Removed 83 rows containing missing values (geom_path).

## Warning: Removed 83 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 84 rows containing missing values (geom_path).

## Warning: Removed 84 rows containing missing values (geom_path).

## Warning: Removed 84 rows containing missing values (geom_path).

## Warning: Removed 84 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 85 rows containing missing values (geom_path).

## Warning: Removed 85 rows containing missing values (geom_path).

## Warning: Removed 85 rows containing missing values (geom_path).

## Warning: Removed 85 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 86 rows containing missing values (geom_path).

## Warning: Removed 86 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 87 rows containing missing values (geom_path).

## Warning: Removed 87 rows containing missing values (geom_path).

## Warning: Removed 87 rows containing missing values (geom_path).

## Warning: Removed 87 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 88 rows containing missing values (geom_path).

## Warning: Removed 88 rows containing missing values (geom_path).

## Warning: Removed 88 rows containing missing values (geom_path).

## Warning: Removed 88 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 89 rows containing missing values (geom_path).

## Warning: Removed 89 rows containing missing values (geom_path).

## Warning: Removed 89 rows containing missing values (geom_path).

## Warning: Removed 89 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 90 rows containing missing values (geom_path).

## Warning: Removed 90 rows containing missing values (geom_path).

## Warning: Removed 90 rows containing missing values (geom_path).

## Warning: Removed 90 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 91 rows containing missing values (geom_path).

## Warning: Removed 91 rows containing missing values (geom_path).

## Warning: Removed 91 rows containing missing values (geom_path).

## Warning: Removed 91 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 92 rows containing missing values (geom_path).

## Warning: Removed 92 rows containing missing values (geom_path).

## Warning: Removed 92 rows containing missing values (geom_path).

## Warning: Removed 92 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 93 rows containing missing values (geom_path).

## Warning: Removed 93 rows containing missing values (geom_path).

## Warning: Removed 93 rows containing missing values (geom_path).

## Warning: Removed 93 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 94 rows containing missing values (geom_path).

## Warning: Removed 94 rows containing missing values (geom_path).

## Warning: Removed 94 rows containing missing values (geom_path).

## Warning: Removed 94 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 95 rows containing missing values (geom_path).

## Warning: Removed 95 rows containing missing values (geom_path).

## Warning: Removed 95 rows containing missing values (geom_path).

## Warning: Removed 95 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 96 rows containing missing values (geom_path).

## Warning: Removed 96 rows containing missing values (geom_path).

## Warning: Removed 96 rows containing missing values (geom_path).

## Warning: Removed 96 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 97 rows containing missing values (geom_path).

## Warning: Removed 97 rows containing missing values (geom_path).

## Warning: Removed 97 rows containing missing values (geom_path).

## Warning: Removed 97 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 98 rows containing missing values (geom_path).

## Warning: Removed 98 rows containing missing values (geom_path).

## Warning: Removed 98 rows containing missing values (geom_path).

## Warning: Removed 98 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 99 rows containing missing values (geom_path).

## Warning: Removed 99 rows containing missing values (geom_path).

## Warning: Removed 99 rows containing missing values (geom_path).

## Warning: Removed 99 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 100 rows containing missing values (geom_path).

## Warning: Removed 100 rows containing missing values (geom_path).

## Warning: Removed 100 rows containing missing values (geom_path).

## Warning: Removed 100 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 101 rows containing missing values (geom_path).

## Warning: Removed 101 rows containing missing values (geom_path).

## Warning: Removed 101 rows containing missing values (geom_path).

## Warning: Removed 101 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 102 rows containing missing values (geom_path).

## Warning: Removed 102 rows containing missing values (geom_path).

## Warning: Removed 102 rows containing missing values (geom_path).

## Warning: Removed 102 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 103 rows containing missing values (geom_path).

## Warning: Removed 103 rows containing missing values (geom_path).

## Warning: Removed 103 rows containing missing values (geom_path).

## Warning: Removed 103 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 104 rows containing missing values (geom_path).

## Warning: Removed 104 rows containing missing values (geom_path).

## Warning: Removed 104 rows containing missing values (geom_path).

## Warning: Removed 104 rows containing missing values (geom_path).

## Warning: Removed 104 rows containing missing values (geom_path).

## Warning: Removed 104 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 105 rows containing missing values (geom_path).

## Warning: Removed 105 rows containing missing values (geom_path).

## Warning: Removed 105 rows containing missing values (geom_path).

## Warning: Removed 105 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 106 rows containing missing values (geom_path).

## Warning: Removed 106 rows containing missing values (geom_path).

## Warning: Removed 106 rows containing missing values (geom_path).

## Warning: Removed 106 rows containing missing values (geom_path).</code></pre>
<pre><code>## Warning: Removed 107 rows containing missing values (geom_path).

## Warning: Removed 107 rows containing missing values (geom_path).</code></pre>
<p><img src="/notes/local-regression_files/figure-html/infant-epan-1.gif" /><!-- --></p>
<p>Fortunately their are methods for determining the optimal bandwidth. We wont dig into them here,<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> but suffice to say most functions for kernel smoothers in Python and R automatically implement them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(infant, <span class="kw">aes</span>(mortal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">kernel =</span> <span class="st">&quot;epanechnikov&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Epanechnikov kernel function&quot;</span>,
       <span class="dt">subtitle =</span> <span class="kw">str_c</span>(<span class="st">&quot;Optimal bandwidth = &quot;</span>,
                        <span class="kw">round</span>(<span class="kw">density</span>(<span class="dt">x =</span> infant<span class="op">$</span>mortal, <span class="dt">kernel =</span> <span class="st">&quot;epanechnikov&quot;</span>)<span class="op">$</span>bw,
                              <span class="dt">digits =</span> <span class="dv">2</span>)),
       <span class="dt">x =</span> <span class="st">&quot;Infant mortality rate (per 1,000)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/infant-epan-optimal-1.png" width="672" /></p>
</div>
</div>
<div id="local-regression" class="section level1">
<h1><span class="header-section-number">3</span> Local regression</h1>
<p>Smoothly varying locally weighted average with kernel weighting improves upon prior approaches, but still suffers from some drawbacks. Primarily, locally-weighted averages are biased on the boundaries of the domain because of the asymmetry of the kernel in that region. This bias can also appear in the interior of the domain if <span class="math inline">\(X\)</span> values are not equally spaced.</p>
<div id="local-linear-regression" class="section level2">
<h2><span class="header-section-number">3.1</span> Local linear regression</h2>
<p>Instead of fitting a constant locally, we can fit a straight line. <strong>Locally weighted scatterplot smoothing</strong> (local regression, LOWESS, or LOESS) fits a separate linear function at each target point <span class="math inline">\(x_0\)</span> using only the nearby training observations. This method estimates a regression line based on localized subsets of the data, building up the global function <span class="math inline">\(f\)</span> point-by-point. It solves the weighted least squares problem at each target point <span class="math inline">\(x_0\)</span>:</p>
<p><span class="math display">\[\min_{\alpha(x_0), \beta(x_0)} \sum_{i=1}^N K_\lambda (x_0, x_i) [y_i - \alpha(x_0) - \beta (x_0)x_i]^2\]</span></p>
<p>The estimate is then <span class="math inline">\(\hat{f}(x_0) = \hat{\alpha} + \hat{\beta}(x_0)x_0\)</span>. Even though we fit an entire linear model to the data in the region, we only use it to evaluate the fit at the single point <span class="math inline">\(x_0\)</span>. We repeat this process for varying <span class="math inline">\(x_0\)</span> to build the full model.</p>
<p>Here is an example of a local linear regression on the <code>ethanol</code> dataset in the <code>lattice</code> package:</p>
<p><img src="/notes/local-regression_files/figure-html/loess-1.png" width="672" /></p>
<p>The LOESS is built up point-by-point. Here, <span class="math inline">\(K_\lambda (x_0, x_i)\)</span> is a tricube kernel with a bandwidth (<span class="math inline">\(\lambda\)</span>) of .75.</p>
<p><img src="/notes/local-regression_files/figure-html/loess_buildup-1.gif" /><!-- --></p>
<p>One important argument you can control with LOESS is the bandwidth, as this dictates how smooth the LOESS function will become. A larger span will result in a smoother curve, but may not be as accurate.</p>
<p><img src="/notes/local-regression_files/figure-html/loess_span-1.gif" /><!-- --></p>
</div>
<div id="local-polynomial-regression" class="section level2">
<h2><span class="header-section-number">3.2</span> Local polynomial regression</h2>
<p>We are not confined only to local linear fits. We can fit local polynomial fits for any degree <span class="math inline">\(d\)</span>:</p>
<p><span class="math display">\[\min_{\alpha(x_0), \beta_j(x_0), j = 1, \ldots, d} \sum_{i=1}^N K_\lambda (x_0, x_i) \left[y_i - \alpha(x_0) - \sum_{j=1}^d \beta_j (x_0)x_i^j \right]^2\]</span></p>
<p>Local polynomial regression tends to fit better (and be less biased) when there are regions of curvature in the true data generating process. Local linear regression will not capture this dynamic as well. The downside is that to decrease bias, local polynomial regression will also increase the variance of the estimates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ethanol, <span class="kw">aes</span>(E, NOx)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">degree =</span> <span class="dv">0</span>),
              <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Zero-order&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">degree =</span> <span class="dv">1</span>),
              <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;First-order&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">degree =</span> <span class="dv">2</span>),
              <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Second-order&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="st">&quot;Zero-order&quot;</span>, <span class="st">&quot;First-order&quot;</span>, <span class="st">&quot;Second-order&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Local linear regression&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Tricube kernel&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Equivalence ratio&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Concentration of nitrogen oxides in micrograms/J&quot;</span>,
       <span class="dt">color =</span> <span class="st">&quot;Degree&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="/notes/local-regression_files/figure-html/loess-poly-1.png" width="672" /></p>
</div>
<div id="higher-dimensional-local-regression" class="section level2">
<h2><span class="header-section-number">3.3</span> Higher dimensional local regression</h2>
<p>Local regression works well with a pair of independent variables <span class="math inline">\(X_1, X_2\)</span>, or <span class="math inline">\(p = 2\)</span>. The neighborhoods are simply two-dimensional with bivariate linear regression models. However, as with nearest neighbors methods, as <span class="math inline">\(p\)</span> increases the number of neighbor training observations decreases rapidly. Once the number of predictors exceeds 3 or 4, local regression is not advised. Likewise, if you have a large number of observations (say <span class="math inline">\(n &gt; 1000\)</span>), estimating all the local regression functions can become computationally intensive, if not infeasible.</p>
</div>
</div>
<div id="session-info" class="section level1 toc-ignore">
<h1><span class="header-section-number">4</span> Session Info</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">session_info</span>()</code></pre></div>
<pre><code>##  Session info 
##  setting  value                       
##  version  R version 3.5.2 (2018-12-20)
##  os       macOS Mojave 10.14.2        
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  ctype    en_US.UTF-8                 
##  tz       America/Chicago             
##  date     2019-02-20                  
## 
##  Packages 
##  package       * version    date       lib
##  assertthat      0.2.0      2017-04-11 [2]
##  backports       1.1.3      2018-12-14 [2]
##  base64enc       0.1-3      2015-07-28 [2]
##  bayesplot       1.6.0      2018-08-02 [2]
##  bindr           0.1.1      2018-03-13 [2]
##  bindrcpp      * 0.2.2      2018-03-29 [1]
##  blogdown        0.10       2019-01-09 [1]
##  bookdown        0.9        2018-12-21 [1]
##  broom         * 0.5.1      2018-12-05 [2]
##  callr           3.1.1      2018-12-21 [2]
##  cellranger      1.1.0      2016-07-27 [2]
##  class           7.3-15     2019-01-01 [2]
##  classInt        0.3-1      2018-12-18 [2]
##  cli             1.0.1      2018-09-25 [1]
##  codetools       0.2-16     2018-12-24 [2]
##  colorspace      1.4-0      2019-01-13 [2]
##  colourpicker    1.0        2017-09-27 [2]
##  crayon          1.3.4      2017-09-16 [2]
##  crosstalk       1.0.0      2016-12-21 [2]
##  data.table      1.12.0     2019-01-13 [2]
##  DBI             1.0.0      2018-05-02 [2]
##  desc            1.2.0      2018-05-01 [2]
##  devtools        2.0.1      2018-10-26 [1]
##  dials         * 0.0.2      2018-12-09 [1]
##  digest          0.6.18     2018-10-10 [1]
##  dplyr         * 0.7.8      2018-11-10 [1]
##  DT              0.5        2018-11-05 [2]
##  dygraphs        1.1.1.6    2018-07-11 [2]
##  e1071           1.7-0.1    2019-01-21 [1]
##  evaluate        0.12       2018-10-09 [2]
##  farver          1.1.0      2018-11-20 [1]
##  forcats       * 0.3.0      2018-02-19 [2]
##  foreach       * 1.4.4      2017-12-12 [2]
##  fs              1.2.6      2018-08-23 [1]
##  gam           * 1.16       2018-07-20 [2]
##  generics        0.0.2      2018-11-29 [1]
##  gganimate     * 1.0.0      2019-01-02 [1]
##  ggplot2       * 3.1.0      2018-10-25 [1]
##  ggridges        0.5.1      2018-09-27 [2]
##  gifski          0.8.6      2018-09-28 [1]
##  glue            1.3.0      2018-07-17 [2]
##  gower           0.1.2      2017-02-23 [2]
##  gridExtra       2.3        2017-09-09 [2]
##  gtable          0.2.0      2016-02-26 [2]
##  gtools          3.8.1      2018-06-26 [2]
##  haven           2.0.0      2018-11-22 [2]
##  here          * 0.1        2017-05-28 [2]
##  hms             0.4.2      2018-03-10 [2]
##  htmltools       0.3.6      2017-04-28 [1]
##  htmlwidgets     1.3        2018-09-30 [2]
##  httpuv          1.4.5.1    2018-12-18 [2]
##  httr            1.4.0      2018-12-11 [2]
##  igraph          1.2.2      2018-07-27 [2]
##  infer         * 0.4.0      2018-11-15 [1]
##  inline          0.3.15     2018-05-18 [2]
##  ipred           0.9-8      2018-11-05 [1]
##  ISLR          * 1.2        2017-10-20 [2]
##  iterators       1.0.10     2018-07-13 [2]
##  janeaustenr     0.1.5      2017-06-10 [2]
##  jsonlite        1.6        2018-12-07 [2]
##  knitr         * 1.21       2018-12-10 [2]
##  labeling        0.3        2014-08-23 [2]
##  later           0.7.5      2018-09-18 [2]
##  lattice       * 0.20-38    2018-11-04 [2]
##  lava            1.6.4      2018-11-25 [2]
##  lazyeval        0.2.1      2017-10-29 [2]
##  lme4            1.1-19     2018-11-10 [2]
##  loo             2.0.0      2018-04-11 [2]
##  lpSolve         5.6.13     2015-09-19 [1]
##  lubridate       1.7.4      2018-04-11 [2]
##  magrittr        1.5        2014-11-22 [2]
##  margins       * 0.3.23     2018-05-22 [2]
##  markdown        0.9        2018-12-07 [2]
##  MASS            7.3-51.1   2018-11-01 [2]
##  Matrix          1.2-15     2018-11-01 [2]
##  matrixStats     0.54.0     2018-07-23 [2]
##  memoise         1.1.0      2017-04-21 [2]
##  mime            0.6        2018-10-05 [1]
##  miniUI          0.1.1.1    2018-05-18 [2]
##  minqa           1.2.4      2014-10-09 [2]
##  modelr          0.1.2      2018-05-11 [2]
##  munsell         0.5.0      2018-06-12 [2]
##  nlme            3.1-137    2018-04-07 [2]
##  nloptr          1.2.1      2018-10-03 [2]
##  nnet            7.3-12     2016-02-02 [2]
##  parsnip       * 0.0.1      2018-11-12 [1]
##  patchwork     * 0.0.1      2018-09-06 [1]
##  pillar          1.3.1      2018-12-15 [2]
##  pkgbuild        1.0.2      2018-10-16 [1]
##  pkgconfig       2.0.2      2018-08-16 [2]
##  pkgload         1.0.2      2018-10-29 [1]
##  plyr            1.8.4      2016-06-08 [2]
##  png             0.1-7      2013-12-03 [2]
##  prediction      0.3.6.1    2018-12-04 [2]
##  prettyunits     1.0.2      2015-07-13 [2]
##  pROC            1.13.0     2018-09-24 [1]
##  processx        3.2.1      2018-12-05 [2]
##  prodlim         2018.04.18 2018-04-18 [2]
##  progress        1.2.0      2018-06-14 [2]
##  promises        1.0.1      2018-04-13 [2]
##  ps              1.3.0      2018-12-21 [2]
##  purrr         * 0.3.0      2019-01-27 [2]
##  R6              2.3.0      2018-10-04 [1]
##  rcfss         * 0.1.5      2019-01-24 [1]
##  Rcpp            1.0.0      2018-11-07 [1]
##  readr         * 1.3.1      2018-12-21 [2]
##  readxl          1.2.0      2018-12-19 [2]
##  recipes       * 0.1.4      2018-11-19 [1]
##  remotes         2.0.2      2018-10-30 [1]
##  reshape2        1.4.3      2017-12-11 [2]
##  rlang           0.3.1      2019-01-08 [1]
##  rmarkdown       1.11       2018-12-08 [2]
##  rpart           4.1-13     2018-02-23 [1]
##  rprojroot       1.3-2      2018-01-03 [2]
##  rsample       * 0.0.4      2019-01-07 [1]
##  rsconnect       0.8.13     2019-01-10 [2]
##  rstan           2.18.2     2018-11-07 [2]
##  rstanarm        2.18.2     2018-11-10 [2]
##  rstantools      1.5.1      2018-08-22 [2]
##  rstudioapi      0.9.0      2019-01-09 [1]
##  rvest           0.3.2      2016-06-17 [2]
##  scales        * 1.0.0      2018-08-09 [1]
##  sessioninfo     1.1.1      2018-11-05 [1]
##  sf              0.7-2      2018-12-20 [1]
##  shiny           1.2.0      2018-11-02 [2]
##  shinyjs         1.0        2018-01-08 [2]
##  shinystan       2.5.0      2018-05-01 [2]
##  shinythemes     1.1.2      2018-11-06 [2]
##  SnowballC       0.6.0      2019-01-15 [2]
##  StanHeaders     2.18.0-1   2018-12-13 [2]
##  stringi         1.2.4      2018-07-20 [2]
##  stringr       * 1.3.1      2018-05-10 [2]
##  survival        2.43-3     2018-11-26 [2]
##  testthat        2.0.1      2018-10-13 [2]
##  threejs         0.3.1      2017-08-13 [2]
##  tibble        * 2.0.1      2019-01-12 [2]
##  tidymodels    * 0.0.2      2018-11-27 [1]
##  tidyposterior   0.0.2      2018-11-15 [1]
##  tidypredict     0.3.0      2019-01-10 [1]
##  tidyr         * 0.8.2.9000 2019-02-11 [1]
##  tidyselect      0.2.5      2018-10-11 [1]
##  tidytext        0.2.0      2018-10-17 [1]
##  tidyverse     * 1.2.1      2017-11-14 [2]
##  timeDate        3043.102   2018-02-21 [2]
##  titanic       * 0.1.0      2015-08-31 [2]
##  tokenizers      0.2.1      2018-03-29 [2]
##  transformr      0.1.1      2018-12-09 [1]
##  tweenr          1.0.1      2018-12-14 [1]
##  units           0.6-2      2018-12-05 [1]
##  usethis         1.4.0      2018-08-14 [1]
##  withr           2.1.2      2018-03-15 [2]
##  xfun            0.4        2018-10-23 [1]
##  xml2            1.2.0      2018-01-24 [2]
##  xtable          1.8-3      2018-08-29 [2]
##  xts             0.11-2     2018-11-05 [2]
##  yaml            2.2.0      2018-07-25 [2]
##  yardstick     * 0.0.2      2018-11-05 [1]
##  zoo             1.8-4      2018-09-19 [2]
##  source                              
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.1)                      
##  Github (thomasp85/patchwork@7fb35b1)
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  local                               
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  Github (tidyverse/tidyr@0b27690)    
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
## 
## [1] /Users/soltoffbc/Library/R/3.5/library
## [2] /Library/Frameworks/R.framework/Versions/3.5/Resources/library</code></pre>
</div>
<div id="references" class="section level1 toc-ignore">
<h1><span class="header-section-number">5</span> References</h1>
<ul>
<li><span class="citation">James et al. (<a href="#ref-james2013introduction">2013</a>)</span></li>
<li><span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-friedman2001elements">2001</a>)</span></li>
</ul>
<div id="refs" class="references">
<div id="ref-friedman2001elements">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. 10. Springer series in statistics New York, NY, USA: <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" class="uri">https://web.stanford.edu/~hastie/ElemStatLearn/</a>.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer. <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>See ESL ch 6.2.<a href="#fnref1"></a></p></li>
</ol>
</div>
