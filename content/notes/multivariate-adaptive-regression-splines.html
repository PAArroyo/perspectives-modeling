---
title: Multivariate adaptive regression splines
date: 2019-02-18T13:30:00-06:00  # Schedule page publish date.
    
draft: false
type: docs

bibliography: [../../static/bib/sources.bib]
csl: [../../static/bib/apa.csl]
link-citations: true

menu:
  notes:
    parent: Moving beyond linearity
    weight: 5
---

<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<div id="TOC">
<ul>
<li><a href="#multivariate-adaptive-regression-splines-mars"><span class="toc-section-number">1</span> Multivariate adaptive regression splines (MARS)</a><ul>
<li><a href="#basis-functions"><span class="toc-section-number">1.1</span> Basis functions</a></li>
<li><a href="#model-construction"><span class="toc-section-number">1.2</span> Model construction</a></li>
<li><a href="#application-to-ames-housing-data"><span class="toc-section-number">1.3</span> Application to Ames housing data</a></li>
</ul></li>
<li><a href="#fitting-a-basic-mars-model"><span class="toc-section-number">2</span> Fitting a basic MARS model</a></li>
<li><a href="#session-info"><span class="toc-section-number">3</span> Session Info</a></li>
<li><a href="#references"><span class="toc-section-number">4</span> References</a></li>
</ul>
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(tidymodels)
<span class="kw">library</span>(rcfss)
<span class="kw">library</span>(titanic)
<span class="kw">library</span>(knitr)
<span class="kw">library</span>(splines)
<span class="kw">library</span>(ISLR)
<span class="kw">library</span>(lattice)
<span class="kw">library</span>(gam)
<span class="kw">library</span>(here)
<span class="kw">library</span>(patchwork)
<span class="kw">library</span>(margins)
<span class="kw">library</span>(earth)

<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="kw">theme_set</span>(<span class="kw">theme_minimal</span>())</code></pre></div>
<div id="multivariate-adaptive-regression-splines-mars" class="section level1">
<h1><span class="header-section-number">1</span> Multivariate adaptive regression splines (MARS)</h1>
<p>MARS is an adaptive procedure for regression which generalizes many of the earlier approaches we saw such as <a href="http://uc-r.github.io/model_selection#stepwise">stepwise regression</a> and <a href="/notes/global-methods/">polynomial regression and step functions</a>. It works well for high-dimensional data (i.e.Â lots of predictors) and can be performed efficiently with cross-validation techniques.</p>
<div id="basis-functions" class="section level2">
<h2><span class="header-section-number">1.1</span> Basis functions</h2>
<p>MARS uses expansions in piecewise linear basis functions of the form <span class="math inline">\((x - t)_+\)</span> and <span class="math inline">\((t - x)_+\)</span>. The <span class="math inline">\(+\)</span> means positive part, so</p>
<p><span class="math display">\[
(x - t)_+ = \begin{cases}
x - t, &amp; \text{if } x &gt; t, \\
0, &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
(t - x)_+ = \begin{cases}
t - x, &amp; \text{if } x &lt; t, \\
0, &amp; \text{otherwise}
\end{cases}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(
  <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;xt&quot;</span>), <span class="dt">fun =</span> <span class="cf">function</span>(x) <span class="kw">ifelse</span>(x <span class="op">&gt;</span><span class="st"> </span>.<span class="dv">5</span>, x <span class="op">-</span><span class="st"> </span>.<span class="dv">5</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;tx&quot;</span>), <span class="dt">fun =</span> <span class="cf">function</span>(x) <span class="kw">ifelse</span>(x <span class="op">&lt;</span><span class="st"> </span>.<span class="dv">5</span>, .<span class="dv">5</span> <span class="op">-</span><span class="st"> </span>x, <span class="dv">0</span>),
                <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>,
                     <span class="dt">labels =</span> <span class="kw">c</span>(<span class="kw">expression</span>((t <span class="op">-</span><span class="st"> </span>x)[<span class="st">&quot;+&quot;</span>]), <span class="kw">expression</span>((x <span class="op">-</span><span class="st"> </span>t)[<span class="st">&quot;+&quot;</span>]))) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;MARS basis functions&quot;</span>,
       <span class="dt">subtitle =</span> <span class="kw">expression</span>(t <span class="op">==</span><span class="st"> </span><span class="fl">0.5</span>),
       <span class="dt">x =</span> <span class="kw">expression</span>(x),
       <span class="dt">y =</span> <span class="st">&quot;Basis function&quot;</span>,
       <span class="dt">color =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/mars-hinge-1.png" width="672" /></p>
<p>Each function is piecewise linear (also known as a linear spline), with a knot at the value <span class="math inline">\(t\)</span>. This distinguishes MARS from traditional splines where the piecewise function is a cubic spline and constrained to be smooth at the knots.</p>
<p>We call these two functions a <strong>reflected pair</strong>. The idea is to form reflected pairs for each input <span class="math inline">\(X_j\)</span> with knots at each observed value <span class="math inline">\(x_{ij}\)</span> of that input. The collection of basis functions is therefore</p>
<p><span class="math display">\[C = \{ (X_j - t)_+, (t - X_j)_+ \}\]</span></p>
<p>for</p>
<p><span class="math display">\[
\begin{align}
t &amp;\in \{ x_{1j}, x_{2j}, \ldots, x_{Nj} \} \\
j &amp;= 1, 2, \ldots, p
\end{align}
\]</span></p>
<p>If all the input values are distinct, then there are <span class="math inline">\(2Np\)</span> basis functions altogether.</p>
</div>
<div id="model-construction" class="section level2">
<h2><span class="header-section-number">1.2</span> Model construction</h2>
<p>MARS uses a forward stepwise linear regression approach, but instead of using the original inputs we use functions from the set <span class="math inline">\(C\)</span> and their products. So the model takes on the form</p>
<p><span class="math display">\[f(X) = \beta_0 + \sum_{m=1}^M \beta_m h_m (X)\]</span></p>
<p>where each <span class="math inline">\(h_m (X)\)</span> is a function in <span class="math inline">\(C\)</span> or a product of two or more functions. Given a choice for <span class="math inline">\(h_m\)</span>, the coefficients are estimated using standard linear regrewssion. We start with only the constant function <span class="math inline">\(h_0 (X) = 1\)</span> in the model, and all functions in <span class="math inline">\(C\)</span> are candidate functions. At each stage, we consider as a new basis function pair all products of a function <span class="math inline">\(h_m\)</span> in the model set <span class="math inline">\(M\)</span> with one of the reflected pairs in <span class="math inline">\(C\)</span>. We add to the model <span class="math inline">\(M\)</span> the term of the form</p>
<p><span class="math display">\[\hat{\beta}_{M+1} h_{\mathcal{l}}(X) \times (X_j - t)_+ + \hat{\beta}_{M + 2} h_{\mathcal{l}}(X) \times (t - X_j)_+, h_{\mathcal{l}}\in M\]</span></p>
<p>that produces the largest decrease in training error, where <span class="math inline">\(\hat{\beta}_{M+1}, \hat{\beta}_{M+2}\)</span> are coefficients estimated by least squares. The winning products are added to the model and the process continues until the model set <span class="math inline">\(M\)</span> contains some preset maximum number of terms.</p>
<p>At this point, we have a large model that overfits the training data, so we use a backward deletion process to remove terms that cause the smallest increase in residual squared error. This produces an estimated best model <span class="math inline">\(\hat{f}_\lambda\)</span> of each size (number of terms) <span class="math inline">\(\lambda\)</span>. We use a generalized form of cross-validation to determine the optimal value for <span class="math inline">\(\lambda\)</span>.</p>
</div>
<div id="application-to-ames-housing-data" class="section level2">
<h2><span class="header-section-number">1.3</span> Application to Ames housing data</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ames_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(AmesHousing<span class="op">::</span><span class="kw">make_ames</span>(), <span class="dt">prop =</span> .<span class="dv">7</span>, <span class="dt">strata =</span> <span class="st">&quot;Sale_Price&quot;</span>)
ames_train &lt;-<span class="st"> </span><span class="kw">training</span>(ames_split)
ames_test  &lt;-<span class="st"> </span><span class="kw">testing</span>(ames_split)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ames_base &lt;-<span class="st"> </span><span class="kw">ggplot</span>(ames_train, <span class="kw">aes</span>(Year_Built, Sale_Price)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> .<span class="dv">05</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> scales<span class="op">::</span>dollar)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">{
  ames_base <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;(A) Linear regression&quot;</span>)
  } <span class="op">+</span><span class="st"> </span>{
    ames_base <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dt">degree =</span> <span class="dv">2</span>), <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">ggtitle</span>(<span class="st">&quot;(B) Degree-2 polynomial regression&quot;</span>)
  } <span class="op">+</span><span class="st"> </span>{
    ames_base <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dt">degree =</span> <span class="dv">3</span>), <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">ggtitle</span>(<span class="st">&quot;(C) Degree-3 polynomial regression&quot;</span>)
  } <span class="op">+</span><span class="st"> </span>{
    ames_base <span class="op">+</span>
<span class="st">      </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">cut_interval</span>(x, <span class="dv">3</span>), <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">      </span><span class="kw">ggtitle</span>(<span class="st">&quot;(D) Step function regression&quot;</span>)
  }</code></pre></div>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/ames-poly-step-1.png" width="672" /></p>
<p>Consider now the MARS approach to this problem. Here we have a simple model <code>Sale_Price ~ Year_Built</code>. The MARS procedure first looks for the single point across the range of <code>Year_Built</code> values where two different linear relationships between <code>Sale_Price</code> and <code>Year_Built</code> achieve the smallest error. For a single knot, the hinge function results in the linear model:</p>
<p><span class="math display">\[
\text{Sale_Price} = \begin{cases}
143913.9 -317 (1972 - \text{Year_Built}) &amp; \text{Year_Built} \leq 1972 \\
143913.9 + 3254 (\text{Year_Built} - 1972) &amp; \text{Year_Built} &gt; 1972
\end{cases}
\]</span></p>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/ames-mars-k1-plot-1.png" width="672" /></p>
<p>Once the first knot has been found, the search continues for a second knot. This new model is:</p>
<p><span class="math display">\[
\text{Sale_Price} = \begin{cases}
146003.4 -365 (1972 - \text{Year_Built}) &amp; \text{Year_Built} \leq 1972 \\
146003.4 + 2911 (\text{Year_Built} - 1972) &amp; 1972 &lt; \text{Year_Built} \leq 2005 \\
146003.4 + 13320.26 (\text{Year_Built} - 2005) &amp; \text{Year_Built} &gt; 2005
\end{cases}
\]</span></p>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/ames-mars-k2-plot-1.png" width="672" /></p>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/ames-mars-plots-1.png" width="672" /></p>
<p>This procedure continues until many knots are found. The result is a highly non-linear pattern, but also a highly overfit model. Consider if we increase the number of knots to 9:</p>
<p><img src="/notes/multivariate-adaptive-regression-splines_files/figure-html/ames-mars-k9-plot-1.png" width="672" /></p>
<p>As a result, after we fit all the hinge functions we remove terms that do not contribute significantly to predictive accuracy. That is, we remove terms which cause the smallest increase in RSS at each stage, producing an estimated best model <span class="math inline">\(\hat{f}_\lambda\)</span> of each size (number of terms) <span class="math inline">\(\lambda\)</span>. This is a process called <strong>pruning</strong> and we use a form of cross-validation to determine the optimal number of knots.</p>
</div>
</div>
<div id="fitting-a-basic-mars-model" class="section level1">
<h1><span class="header-section-number">2</span> Fitting a basic MARS model</h1>
<ul>
<li>For R, see <a href="http://uc-r.github.io/mars">Multivariate Adaptive Regression Splines</a> and the <code>earth</code> package</li>
<li>For Python, see <a href="https://github.com/scikit-learn-contrib/py-earth"><code>py-earth</code></a></li>
</ul>
</div>
<div id="session-info" class="section level1 toc-ignore">
<h1><span class="header-section-number">3</span> Session Info</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">session_info</span>()</code></pre></div>
<pre><code>## â Session info ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
##  setting  value                       
##  version  R version 3.5.2 (2018-12-20)
##  os       macOS Mojave 10.14.2        
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  ctype    en_US.UTF-8                 
##  tz       America/Chicago             
##  date     2019-02-19                  
## 
## â Packages ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
##  package       * version    date       lib
##  assertthat      0.2.0      2017-04-11 [2]
##  backports       1.1.3      2018-12-14 [2]
##  base64enc       0.1-3      2015-07-28 [2]
##  bayesplot       1.6.0      2018-08-02 [2]
##  bindr           0.1.1      2018-03-13 [2]
##  bindrcpp      * 0.2.2      2018-03-29 [1]
##  blogdown        0.10       2019-01-09 [1]
##  bookdown        0.9        2018-12-21 [1]
##  broom         * 0.5.1      2018-12-05 [2]
##  callr           3.1.1      2018-12-21 [2]
##  cellranger      1.1.0      2016-07-27 [2]
##  class           7.3-15     2019-01-01 [2]
##  cli             1.0.1      2018-09-25 [1]
##  codetools       0.2-16     2018-12-24 [2]
##  colorspace      1.4-0      2019-01-13 [2]
##  colourpicker    1.0        2017-09-27 [2]
##  crayon          1.3.4      2017-09-16 [2]
##  crosstalk       1.0.0      2016-12-21 [2]
##  data.table      1.12.0     2019-01-13 [2]
##  desc            1.2.0      2018-05-01 [2]
##  devtools        2.0.1      2018-10-26 [1]
##  dials         * 0.0.2      2018-12-09 [1]
##  digest          0.6.18     2018-10-10 [1]
##  dplyr         * 0.7.8      2018-11-10 [1]
##  DT              0.5        2018-11-05 [2]
##  dygraphs        1.1.1.6    2018-07-11 [2]
##  earth         * 4.7.0      2019-01-03 [1]
##  evaluate        0.12       2018-10-09 [2]
##  forcats       * 0.3.0      2018-02-19 [2]
##  foreach       * 1.4.4      2017-12-12 [2]
##  fs              1.2.6      2018-08-23 [1]
##  gam           * 1.16       2018-07-20 [2]
##  generics        0.0.2      2018-11-29 [1]
##  ggplot2       * 3.1.0      2018-10-25 [1]
##  ggridges        0.5.1      2018-09-27 [2]
##  glue            1.3.0      2018-07-17 [2]
##  gower           0.1.2      2017-02-23 [2]
##  gridExtra       2.3        2017-09-09 [2]
##  gtable          0.2.0      2016-02-26 [2]
##  gtools          3.8.1      2018-06-26 [2]
##  haven           2.0.0      2018-11-22 [2]
##  here          * 0.1        2017-05-28 [2]
##  hms             0.4.2      2018-03-10 [2]
##  htmltools       0.3.6      2017-04-28 [1]
##  htmlwidgets     1.3        2018-09-30 [2]
##  httpuv          1.4.5.1    2018-12-18 [2]
##  httr            1.4.0      2018-12-11 [2]
##  igraph          1.2.2      2018-07-27 [2]
##  infer         * 0.4.0      2018-11-15 [1]
##  inline          0.3.15     2018-05-18 [2]
##  ipred           0.9-8      2018-11-05 [1]
##  ISLR          * 1.2        2017-10-20 [2]
##  iterators       1.0.10     2018-07-13 [2]
##  janeaustenr     0.1.5      2017-06-10 [2]
##  jsonlite        1.6        2018-12-07 [2]
##  knitr         * 1.21       2018-12-10 [2]
##  labeling        0.3        2014-08-23 [2]
##  later           0.7.5      2018-09-18 [2]
##  lattice       * 0.20-38    2018-11-04 [2]
##  lava            1.6.4      2018-11-25 [2]
##  lazyeval        0.2.1      2017-10-29 [2]
##  lme4            1.1-19     2018-11-10 [2]
##  loo             2.0.0      2018-04-11 [2]
##  lubridate       1.7.4      2018-04-11 [2]
##  magrittr        1.5        2014-11-22 [2]
##  margins       * 0.3.23     2018-05-22 [2]
##  markdown        0.9        2018-12-07 [2]
##  MASS            7.3-51.1   2018-11-01 [2]
##  Matrix          1.2-15     2018-11-01 [2]
##  matrixStats     0.54.0     2018-07-23 [2]
##  memoise         1.1.0      2017-04-21 [2]
##  mime            0.6        2018-10-05 [1]
##  miniUI          0.1.1.1    2018-05-18 [2]
##  minqa           1.2.4      2014-10-09 [2]
##  modelr          0.1.2      2018-05-11 [2]
##  munsell         0.5.0      2018-06-12 [2]
##  nlme            3.1-137    2018-04-07 [2]
##  nloptr          1.2.1      2018-10-03 [2]
##  nnet            7.3-12     2016-02-02 [2]
##  parsnip       * 0.0.1      2018-11-12 [1]
##  patchwork     * 0.0.1      2018-09-06 [1]
##  pillar          1.3.1      2018-12-15 [2]
##  pkgbuild        1.0.2      2018-10-16 [1]
##  pkgconfig       2.0.2      2018-08-16 [2]
##  pkgload         1.0.2      2018-10-29 [1]
##  plotmo        * 3.5.2      2019-01-02 [1]
##  plotrix       * 3.7-4      2018-10-03 [2]
##  plyr            1.8.4      2016-06-08 [2]
##  prediction      0.3.6.1    2018-12-04 [2]
##  prettyunits     1.0.2      2015-07-13 [2]
##  pROC            1.13.0     2018-09-24 [1]
##  processx        3.2.1      2018-12-05 [2]
##  prodlim         2018.04.18 2018-04-18 [2]
##  promises        1.0.1      2018-04-13 [2]
##  ps              1.3.0      2018-12-21 [2]
##  purrr         * 0.3.0      2019-01-27 [2]
##  R6              2.3.0      2018-10-04 [1]
##  rcfss         * 0.1.5      2019-01-24 [1]
##  Rcpp            1.0.0      2018-11-07 [1]
##  readr         * 1.3.1      2018-12-21 [2]
##  readxl          1.2.0      2018-12-19 [2]
##  recipes       * 0.1.4      2018-11-19 [1]
##  remotes         2.0.2      2018-10-30 [1]
##  reshape2        1.4.3      2017-12-11 [2]
##  rlang           0.3.1      2019-01-08 [1]
##  rmarkdown       1.11       2018-12-08 [2]
##  rpart           4.1-13     2018-02-23 [1]
##  rprojroot       1.3-2      2018-01-03 [2]
##  rsample       * 0.0.4      2019-01-07 [1]
##  rsconnect       0.8.13     2019-01-10 [2]
##  rstan           2.18.2     2018-11-07 [2]
##  rstanarm        2.18.2     2018-11-10 [2]
##  rstantools      1.5.1      2018-08-22 [2]
##  rstudioapi      0.9.0      2019-01-09 [1]
##  rvest           0.3.2      2016-06-17 [2]
##  scales        * 1.0.0      2018-08-09 [1]
##  sessioninfo     1.1.1      2018-11-05 [1]
##  shiny           1.2.0      2018-11-02 [2]
##  shinyjs         1.0        2018-01-08 [2]
##  shinystan       2.5.0      2018-05-01 [2]
##  shinythemes     1.1.2      2018-11-06 [2]
##  SnowballC       0.6.0      2019-01-15 [2]
##  StanHeaders     2.18.0-1   2018-12-13 [2]
##  stringi         1.2.4      2018-07-20 [2]
##  stringr       * 1.3.1      2018-05-10 [2]
##  survival        2.43-3     2018-11-26 [2]
##  TeachingDemos * 2.10       2016-02-12 [2]
##  testthat        2.0.1      2018-10-13 [2]
##  threejs         0.3.1      2017-08-13 [2]
##  tibble        * 2.0.1      2019-01-12 [2]
##  tidymodels    * 0.0.2      2018-11-27 [1]
##  tidyposterior   0.0.2      2018-11-15 [1]
##  tidypredict     0.3.0      2019-01-10 [1]
##  tidyr         * 0.8.2.9000 2019-02-11 [1]
##  tidyselect      0.2.5      2018-10-11 [1]
##  tidytext        0.2.0      2018-10-17 [1]
##  tidyverse     * 1.2.1      2017-11-14 [2]
##  timeDate        3043.102   2018-02-21 [2]
##  titanic       * 0.1.0      2015-08-31 [2]
##  tokenizers      0.2.1      2018-03-29 [2]
##  usethis         1.4.0      2018-08-14 [1]
##  withr           2.1.2      2018-03-15 [2]
##  xfun            0.4        2018-10-23 [1]
##  xml2            1.2.0      2018-01-24 [2]
##  xtable          1.8-3      2018-08-29 [2]
##  xts             0.11-2     2018-11-05 [2]
##  yaml            2.2.0      2018-07-25 [2]
##  yardstick     * 0.0.2      2018-11-05 [1]
##  zoo             1.8-4      2018-09-19 [2]
##  source                              
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.1)                      
##  Github (thomasp85/patchwork@7fb35b1)
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  local                               
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  CRAN (R 3.5.1)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.2)                      
##  Github (tidyverse/tidyr@0b27690)    
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
##  CRAN (R 3.5.0)                      
## 
## [1] /Users/soltoffbc/Library/R/3.5/library
## [2] /Library/Frameworks/R.framework/Versions/3.5/Resources/library</code></pre>
</div>
<div id="references" class="section level1 toc-ignore">
<h1><span class="header-section-number">4</span> References</h1>
<ul>
<li><span class="citation">James et al. (<a href="#ref-james2013introduction">2013</a>)</span></li>
<li><span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-friedman2001elements">2001</a>)</span></li>
</ul>
<div id="refs" class="references">
<div id="ref-friedman2001elements">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. 10. Springer series in statistics New York, NY, USA: <a href="https://web.stanford.edu/~hastie/ElemStatLearn/" class="uri">https://web.stanford.edu/~hastie/ElemStatLearn/</a>.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer. <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a>.</p>
</div>
</div>
</div>
